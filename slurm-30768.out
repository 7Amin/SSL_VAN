/var/spool/slurmd/job30768/slurm_script: line 10: cd: SSL_VAN: No such file or directory

----------------------------------------------------------------------------
  cuda:
----------------------------------------------------------------------------
     Versions:
        cuda/10.2
        cuda/11.0
        cuda/11.2
        cuda/11.3
        cuda/11.4
        cuda/11.5
        cuda/11.6
        cuda/12.0

----------------------------------------------------------------------------
  For detailed information about a specific "cuda" package (including how to load the modules) use the module's full name.
  Note that names that have a trailing (E) are extensions provided by other modules.
  For example:

     $ module spider cuda/12.0
----------------------------------------------------------------------------

 


CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.
To initialize your shell, run

    $ conda init <SHELL_NAME>

Currently supported shells are:
  - bash
  - fish
  - tcsh
  - xonsh
  - zsh
  - powershell

See 'conda init --help' for more information and options.

IMPORTANT: You may need to close and restart your shell after running 'conda init'.


/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
Found total gpus 2
/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/monai/transforms/post/array.py:176: UserWarning: `to_onehot=True/False` is deprecated, please use `to_onehot=num_classes` instead.
  warnings.warn("`to_onehot=True/False` is deprecated, please use `to_onehot=num_classes` instead.")
/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/monai/transforms/post/array.py:176: UserWarning: `to_onehot=True/False` is deprecated, please use `to_onehot=num_classes` instead.
  warnings.warn("`to_onehot=True/False` is deprecated, please use `to_onehot=num_classes` instead.")
input_list/dataset_BTCV_List.json
0  gpu 0
Batch size is: 8 epochs 5000
Total parameters count 23127538
Writing Tensorboard logs to  ./run/BTCV/test_log
0 Mon Mar 13 20:51:36 2023 Epoch: 0
input_list/dataset_BTCV_List.json
1  gpu 1
Total parameters count 23127538
1 Mon Mar 13 20:51:36 2023 Epoch: 0
1 Mon Mar 13 20:52:04 2023 Epoch: 1
1 Mon Mar 13 20:52:25 2023 Epoch: 2
1 Mon Mar 13 20:52:45 2023 Epoch: 3
1 Mon Mar 13 20:53:03 2023 Epoch: 4
1 Mon Mar 13 20:53:23 2023 Epoch: 5
1 Mon Mar 13 20:53:44 2023 Epoch: 6
1 Mon Mar 13 20:54:05 2023 Epoch: 7
1 Mon Mar 13 20:54:26 2023 Epoch: 8
1 Mon Mar 13 20:54:47 2023 Epoch: 9
1 Mon Mar 13 20:55:06 2023 Epoch: 10
1 Mon Mar 13 20:55:26 2023 Epoch: 11
1 Mon Mar 13 20:55:47 2023 Epoch: 12
1 Mon Mar 13 20:56:07 2023 Epoch: 13
1 Mon Mar 13 20:56:27 2023 Epoch: 14
1 Mon Mar 13 20:56:47 2023 Epoch: 15
1 Mon Mar 13 20:57:06 2023 Epoch: 16
1 Mon Mar 13 20:57:25 2023 Epoch: 17
1 Mon Mar 13 20:57:44 2023 Epoch: 18
1 Mon Mar 13 20:58:05 2023 Epoch: 19
1 Mon Mar 13 20:58:26 2023 Epoch: 20
1 Mon Mar 13 20:58:45 2023 Epoch: 21
1 Mon Mar 13 20:59:07 2023 Epoch: 22
1 Mon Mar 13 20:59:27 2023 Epoch: 23
1 Mon Mar 13 20:59:48 2023 Epoch: 24
1 Mon Mar 13 21:00:09 2023 Epoch: 25
1 Mon Mar 13 21:00:28 2023 Epoch: 26
1 Mon Mar 13 21:00:48 2023 Epoch: 27
1 Mon Mar 13 21:01:10 2023 Epoch: 28
1 Mon Mar 13 21:01:30 2023 Epoch: 29
1 Mon Mar 13 21:01:49 2023 Epoch: 30
1 Mon Mar 13 21:02:10 2023 Epoch: 31
1 Mon Mar 13 21:02:31 2023 Epoch: 32
1 Mon Mar 13 21:02:51 2023 Epoch: 33
1 Mon Mar 13 21:03:10 2023 Epoch: 34
1 Mon Mar 13 21:03:30 2023 Epoch: 35
1 Mon Mar 13 21:03:51 2023 Epoch: 36
1 Mon Mar 13 21:04:10 2023 Epoch: 37
1 Mon Mar 13 21:04:31 2023 Epoch: 38
1 Mon Mar 13 21:04:50 2023 Epoch: 39
1 Mon Mar 13 21:05:10 2023 Epoch: 40
1 Mon Mar 13 21:05:32 2023 Epoch: 41
1 Mon Mar 13 21:05:52 2023 Epoch: 42
1 Mon Mar 13 21:06:12 2023 Epoch: 43
1 Mon Mar 13 21:06:32 2023 Epoch: 44
1 Mon Mar 13 21:06:52 2023 Epoch: 45
1 Mon Mar 13 21:07:13 2023 Epoch: 46
1 Mon Mar 13 21:07:33 2023 Epoch: 47
1 Mon Mar 13 21:07:54 2023 Epoch: 48
1 Mon Mar 13 21:08:15 2023 Epoch: 49
1 Mon Mar 13 21:08:35 2023 Epoch: 50
1 Mon Mar 13 21:08:55 2023 Epoch: 51
1 Mon Mar 13 21:09:14 2023 Epoch: 52
1 Mon Mar 13 21:09:36 2023 Epoch: 53
1 Mon Mar 13 21:09:54 2023 Epoch: 54
1 Mon Mar 13 21:10:14 2023 Epoch: 55
1 Mon Mar 13 21:10:34 2023 Epoch: 56
1 Mon Mar 13 21:10:52 2023 Epoch: 57
1 Mon Mar 13 21:11:12 2023 Epoch: 58
1 Mon Mar 13 21:11:31 2023 Epoch: 59
1 Mon Mar 13 21:11:52 2023 Epoch: 60
1 Mon Mar 13 21:12:11 2023 Epoch: 61
1 Mon Mar 13 21:12:31 2023 Epoch: 62
1 Mon Mar 13 21:12:53 2023 Epoch: 63
1 Mon Mar 13 21:13:14 2023 Epoch: 64
1 Mon Mar 13 21:13:35 2023 Epoch: 65
1 Mon Mar 13 21:13:55 2023 Epoch: 66
1 Mon Mar 13 21:14:15 2023 Epoch: 67
1 Mon Mar 13 21:14:35 2023 Epoch: 68
1 Mon Mar 13 21:14:54 2023 Epoch: 69
1 Mon Mar 13 21:15:13 2023 Epoch: 70
1 Mon Mar 13 21:15:32 2023 Epoch: 71
1 Mon Mar 13 21:15:50 2023 Epoch: 72
1 Mon Mar 13 21:16:10 2023 Epoch: 73
1 Mon Mar 13 21:16:30 2023 Epoch: 74
1 Mon Mar 13 21:16:51 2023 Epoch: 75
1 Mon Mar 13 21:17:12 2023 Epoch: 76
1 Mon Mar 13 21:17:32 2023 Epoch: 77
1 Mon Mar 13 21:17:52 2023 Epoch: 78
1 Mon Mar 13 21:18:13 2023 Epoch: 79
1 Mon Mar 13 21:18:34 2023 Epoch: 80
1 Mon Mar 13 21:18:55 2023 Epoch: 81
1 Mon Mar 13 21:19:14 2023 Epoch: 82
1 Mon Mar 13 21:19:33 2023 Epoch: 83
1 Mon Mar 13 21:19:52 2023 Epoch: 84
1 Mon Mar 13 21:20:12 2023 Epoch: 85
1 Mon Mar 13 21:20:32 2023 Epoch: 86
1 Mon Mar 13 21:20:53 2023 Epoch: 87
1 Mon Mar 13 21:21:14 2023 Epoch: 88
1 Mon Mar 13 21:21:35 2023 Epoch: 89
1 Mon Mar 13 21:21:56 2023 Epoch: 90
1 Mon Mar 13 21:22:16 2023 Epoch: 91
1 Mon Mar 13 21:22:37 2023 Epoch: 92
1 Mon Mar 13 21:22:57 2023 Epoch: 93
1 Mon Mar 13 21:23:16 2023 Epoch: 94
1 Mon Mar 13 21:23:36 2023 Epoch: 95
1 Mon Mar 13 21:23:57 2023 Epoch: 96
1 Mon Mar 13 21:24:16 2023 Epoch: 97
1 Mon Mar 13 21:24:36 2023 Epoch: 98
1 Mon Mar 13 21:24:57 2023 Epoch: 99
Epoch 0/5000 0/2 loss: 3.6239 time 25.07s
Epoch 0/5000 1/2 loss: 3.6250 time 3.20s
Final training  0/4999 loss: 3.6250 time 28.28s
0 Mon Mar 13 20:52:04 2023 Epoch: 1
Epoch 1/5000 0/2 loss: 3.6292 time 20.36s
Epoch 1/5000 1/2 loss: 3.6279 time 0.46s
Final training  1/4999 loss: 3.6279 time 20.82s
0 Mon Mar 13 20:52:25 2023 Epoch: 2
Epoch 2/5000 0/2 loss: 3.6252 time 18.91s
Epoch 2/5000 1/2 loss: 3.6243 time 0.46s
Final training  2/4999 loss: 3.6243 time 19.37s
0 Mon Mar 13 20:52:45 2023 Epoch: 3
Epoch 3/5000 0/2 loss: 3.6251 time 18.19s
Epoch 3/5000 1/2 loss: 3.6231 time 0.45s
Final training  3/4999 loss: 3.6231 time 18.65s
0 Mon Mar 13 20:53:03 2023 Epoch: 4
Epoch 4/5000 0/2 loss: 3.6253 time 18.86s
Epoch 4/5000 1/2 loss: 3.6240 time 0.46s
Final training  4/4999 loss: 3.6240 time 19.32s
0 Mon Mar 13 20:53:23 2023 Epoch: 5
Epoch 5/5000 0/2 loss: 3.6240 time 20.99s
Epoch 5/5000 1/2 loss: 3.6254 time 0.45s
Final training  5/4999 loss: 3.6254 time 21.44s
0 Mon Mar 13 20:53:44 2023 Epoch: 6
Epoch 6/5000 0/2 loss: 3.6255 time 20.53s
Epoch 6/5000 1/2 loss: 3.6240 time 0.45s
Final training  6/4999 loss: 3.6240 time 20.99s
0 Mon Mar 13 20:54:05 2023 Epoch: 7
Epoch 7/5000 0/2 loss: 3.6245 time 20.04s
Epoch 7/5000 1/2 loss: 3.6242 time 0.46s
Final training  7/4999 loss: 3.6242 time 20.50s
0 Mon Mar 13 20:54:26 2023 Epoch: 8
Epoch 8/5000 0/2 loss: 3.6248 time 20.54s
Epoch 8/5000 1/2 loss: 3.6255 time 0.45s
Final training  8/4999 loss: 3.6255 time 21.00s
0 Mon Mar 13 20:54:47 2023 Epoch: 9
Epoch 9/5000 0/2 loss: 3.6234 time 19.18s
Epoch 9/5000 1/2 loss: 3.6242 time 0.45s
Final training  9/4999 loss: 3.6242 time 19.63s
0 Mon Mar 13 20:55:06 2023 Epoch: 10
Epoch 10/5000 0/2 loss: 3.6268 time 19.68s
Epoch 10/5000 1/2 loss: 3.6256 time 0.45s
Final training  10/4999 loss: 3.6256 time 20.13s
0 Mon Mar 13 20:55:26 2023 Epoch: 11
Epoch 11/5000 0/2 loss: 3.6238 time 20.07s
Epoch 11/5000 1/2 loss: 3.6239 time 0.45s
Final training  11/4999 loss: 3.6239 time 20.53s
0 Mon Mar 13 20:55:47 2023 Epoch: 12
Epoch 12/5000 0/2 loss: 3.6244 time 19.17s
Epoch 12/5000 1/2 loss: 3.6219 time 0.46s
Final training  12/4999 loss: 3.6219 time 19.63s
0 Mon Mar 13 20:56:07 2023 Epoch: 13
Epoch 13/5000 0/2 loss: 3.6237 time 19.77s
Epoch 13/5000 1/2 loss: 3.6254 time 0.46s
Final training  13/4999 loss: 3.6254 time 20.23s
0 Mon Mar 13 20:56:27 2023 Epoch: 14
Epoch 14/5000 0/2 loss: 3.6223 time 19.56s
Epoch 14/5000 1/2 loss: 3.6218 time 0.45s
Final training  14/4999 loss: 3.6218 time 20.02s
0 Mon Mar 13 20:56:47 2023 Epoch: 15
Epoch 15/5000 0/2 loss: 3.6224 time 19.15s
Epoch 15/5000 1/2 loss: 3.6213 time 0.45s
Final training  15/4999 loss: 3.6213 time 19.61s
0 Mon Mar 13 20:57:06 2023 Epoch: 16
Epoch 16/5000 0/2 loss: 3.6232 time 18.10s
Epoch 16/5000 1/2 loss: 3.6224 time 0.46s
Final training  16/4999 loss: 3.6224 time 18.55s
0 Mon Mar 13 20:57:25 2023 Epoch: 17
Epoch 17/5000 0/2 loss: 3.6245 time 18.41s
Epoch 17/5000 1/2 loss: 3.6225 time 0.46s
Final training  17/4999 loss: 3.6225 time 18.87s
0 Mon Mar 13 20:57:44 2023 Epoch: 18
Epoch 18/5000 0/2 loss: 3.6221 time 20.48s
Epoch 18/5000 1/2 loss: 3.6225 time 0.46s
Final training  18/4999 loss: 3.6225 time 20.94s
0 Mon Mar 13 20:58:05 2023 Epoch: 19
Epoch 19/5000 0/2 loss: 3.6198 time 20.65s
Epoch 19/5000 1/2 loss: 3.6205 time 0.46s
Final training  19/4999 loss: 3.6205 time 21.11s
0 Mon Mar 13 20:58:26 2023 Epoch: 20
Epoch 20/5000 0/2 loss: 3.6196 time 19.14s
Epoch 20/5000 1/2 loss: 3.6191 time 0.46s
Final training  20/4999 loss: 3.6191 time 19.60s
0 Mon Mar 13 20:58:45 2023 Epoch: 21
Epoch 21/5000 0/2 loss: 3.6214 time 20.67s
Epoch 21/5000 1/2 loss: 3.6208 time 0.46s
Final training  21/4999 loss: 3.6208 time 21.13s
0 Mon Mar 13 20:59:07 2023 Epoch: 22
Epoch 22/5000 0/2 loss: 3.6167 time 20.35s
Epoch 22/5000 1/2 loss: 3.6171 time 0.46s
Final training  22/4999 loss: 3.6171 time 20.81s
0 Mon Mar 13 20:59:27 2023 Epoch: 23
Epoch 23/5000 0/2 loss: 3.6173 time 20.29s
Epoch 23/5000 1/2 loss: 3.6173 time 0.46s
Final training  23/4999 loss: 3.6173 time 20.75s
0 Mon Mar 13 20:59:48 2023 Epoch: 24
Epoch 24/5000 0/2 loss: 3.6140 time 20.27s
Epoch 24/5000 1/2 loss: 3.6140 time 0.46s
Final training  24/4999 loss: 3.6140 time 20.73s
0 Mon Mar 13 21:00:09 2023 Epoch: 25
Epoch 25/5000 0/2 loss: 3.6126 time 18.42s
Epoch 25/5000 1/2 loss: 3.6125 time 0.45s
Final training  25/4999 loss: 3.6125 time 18.88s
0 Mon Mar 13 21:00:28 2023 Epoch: 26
Epoch 26/5000 0/2 loss: 3.6095 time 20.15s
Epoch 26/5000 1/2 loss: 3.6089 time 0.46s
Final training  26/4999 loss: 3.6089 time 20.61s
0 Mon Mar 13 21:00:48 2023 Epoch: 27
Epoch 27/5000 0/2 loss: 3.6053 time 20.78s
Epoch 27/5000 1/2 loss: 3.6050 time 0.46s
Final training  27/4999 loss: 3.6050 time 21.23s
0 Mon Mar 13 21:01:10 2023 Epoch: 28
Epoch 28/5000 0/2 loss: 3.5996 time 19.69s
Epoch 28/5000 1/2 loss: 3.5990 time 0.45s
Final training  28/4999 loss: 3.5990 time 20.14s
0 Mon Mar 13 21:01:30 2023 Epoch: 29
Epoch 29/5000 0/2 loss: 3.5937 time 18.86s
Epoch 29/5000 1/2 loss: 3.5921 time 0.46s
Final training  29/4999 loss: 3.5921 time 19.32s
0 Mon Mar 13 21:01:49 2023 Epoch: 30
Epoch 30/5000 0/2 loss: 3.5864 time 20.89s
Epoch 30/5000 1/2 loss: 3.5831 time 0.46s
Final training  30/4999 loss: 3.5831 time 21.35s
0 Mon Mar 13 21:02:10 2023 Epoch: 31
Epoch 31/5000 0/2 loss: 3.5743 time 19.81s
Epoch 31/5000 1/2 loss: 3.5707 time 0.45s
Final training  31/4999 loss: 3.5707 time 20.27s
0 Mon Mar 13 21:02:31 2023 Epoch: 32
Epoch 32/5000 0/2 loss: 3.5602 time 19.41s
Epoch 32/5000 1/2 loss: 3.5555 time 0.46s
Final training  32/4999 loss: 3.5555 time 19.86s
0 Mon Mar 13 21:02:51 2023 Epoch: 33
Epoch 33/5000 0/2 loss: 3.5404 time 18.97s
Epoch 33/5000 1/2 loss: 3.5350 time 0.46s
Final training  33/4999 loss: 3.5350 time 19.42s
0 Mon Mar 13 21:03:10 2023 Epoch: 34
Epoch 34/5000 0/2 loss: 3.5168 time 20.08s
Epoch 34/5000 1/2 loss: 3.5098 time 0.46s
Final training  34/4999 loss: 3.5098 time 20.53s
0 Mon Mar 13 21:03:30 2023 Epoch: 35
Epoch 35/5000 0/2 loss: 3.4879 time 20.22s
Epoch 35/5000 1/2 loss: 3.4767 time 0.45s
Final training  35/4999 loss: 3.4767 time 20.68s
0 Mon Mar 13 21:03:51 2023 Epoch: 36
Epoch 36/5000 0/2 loss: 3.4464 time 18.72s
Epoch 36/5000 1/2 loss: 3.4345 time 0.45s
Final training  36/4999 loss: 3.4345 time 19.18s
0 Mon Mar 13 21:04:10 2023 Epoch: 37
Epoch 37/5000 0/2 loss: 3.3919 time 19.90s
Epoch 37/5000 1/2 loss: 3.3806 time 0.46s
Final training  37/4999 loss: 3.3806 time 20.36s
0 Mon Mar 13 21:04:31 2023 Epoch: 38
Epoch 38/5000 0/2 loss: 3.3288 time 18.93s
Epoch 38/5000 1/2 loss: 3.3173 time 0.45s
Final training  38/4999 loss: 3.3173 time 19.38s
0 Mon Mar 13 21:04:50 2023 Epoch: 39
Epoch 39/5000 0/2 loss: 3.2573 time 19.55s
Epoch 39/5000 1/2 loss: 3.2262 time 0.46s
Final training  39/4999 loss: 3.2262 time 20.01s
0 Mon Mar 13 21:05:10 2023 Epoch: 40
Epoch 40/5000 0/2 loss: 3.1571 time 21.29s
Epoch 40/5000 1/2 loss: 3.1256 time 0.46s
Final training  40/4999 loss: 3.1256 time 21.75s
0 Mon Mar 13 21:05:32 2023 Epoch: 41
Epoch 41/5000 0/2 loss: 3.0535 time 19.25s
Epoch 41/5000 1/2 loss: 3.0177 time 0.46s
Final training  41/4999 loss: 3.0177 time 19.71s
0 Mon Mar 13 21:05:52 2023 Epoch: 42
Epoch 42/5000 0/2 loss: 2.9079 time 20.42s
Epoch 42/5000 1/2 loss: 2.8861 time 0.46s
Final training  42/4999 loss: 2.8861 time 20.88s
0 Mon Mar 13 21:06:12 2023 Epoch: 43
Epoch 43/5000 0/2 loss: 2.7823 time 18.64s
Epoch 43/5000 1/2 loss: 2.7413 time 0.46s
Final training  43/4999 loss: 2.7413 time 19.10s
0 Mon Mar 13 21:06:32 2023 Epoch: 44
Epoch 44/5000 0/2 loss: 2.6224 time 19.89s
Epoch 44/5000 1/2 loss: 2.5887 time 0.46s
Final training  44/4999 loss: 2.5887 time 20.35s
0 Mon Mar 13 21:06:52 2023 Epoch: 45
Epoch 45/5000 0/2 loss: 2.5076 time 21.08s
Epoch 45/5000 1/2 loss: 2.4411 time 0.46s
Final training  45/4999 loss: 2.4411 time 21.54s
0 Mon Mar 13 21:07:13 2023 Epoch: 46
Epoch 46/5000 0/2 loss: 2.3764 time 19.46s
Epoch 46/5000 1/2 loss: 2.3595 time 0.46s
Final training  46/4999 loss: 2.3595 time 19.92s
0 Mon Mar 13 21:07:33 2023 Epoch: 47
Epoch 47/5000 0/2 loss: 2.2855 time 19.98s
Epoch 47/5000 1/2 loss: 2.3147 time 0.45s
Final training  47/4999 loss: 2.3147 time 20.44s
0 Mon Mar 13 21:07:54 2023 Epoch: 48
Epoch 48/5000 0/2 loss: 2.1607 time 20.78s
Epoch 48/5000 1/2 loss: 2.1852 time 0.46s
Final training  48/4999 loss: 2.1852 time 21.24s
0 Mon Mar 13 21:08:15 2023 Epoch: 49
Epoch 49/5000 0/2 loss: 2.0271 time 19.03s
Epoch 49/5000 1/2 loss: 2.0348 time 0.45s
Final training  49/4999 loss: 2.0348 time 19.49s
0 Mon Mar 13 21:08:35 2023 Epoch: 50
Epoch 50/5000 0/2 loss: 2.0784 time 19.68s
Epoch 50/5000 1/2 loss: 2.0516 time 0.46s
Final training  50/4999 loss: 2.0516 time 20.14s
0 Mon Mar 13 21:08:55 2023 Epoch: 51
Epoch 51/5000 0/2 loss: 1.9675 time 19.19s
Epoch 51/5000 1/2 loss: 2.0197 time 0.46s
Final training  51/4999 loss: 2.0197 time 19.65s
0 Mon Mar 13 21:09:14 2023 Epoch: 52
Epoch 52/5000 0/2 loss: 1.9122 time 21.02s
Epoch 52/5000 1/2 loss: 1.8963 time 0.45s
Final training  52/4999 loss: 1.8963 time 21.48s
0 Mon Mar 13 21:09:36 2023 Epoch: 53
Epoch 53/5000 0/2 loss: 1.9254 time 18.15s
Epoch 53/5000 1/2 loss: 1.7811 time 0.45s
Final training  53/4999 loss: 1.7811 time 18.61s
0 Mon Mar 13 21:09:54 2023 Epoch: 54
Epoch 54/5000 0/2 loss: 1.9160 time 18.95s
Epoch 54/5000 1/2 loss: 1.8881 time 0.46s
Final training  54/4999 loss: 1.8881 time 19.40s
0 Mon Mar 13 21:10:14 2023 Epoch: 55
Epoch 55/5000 0/2 loss: 1.7381 time 19.34s
Epoch 55/5000 1/2 loss: 1.7601 time 0.46s
Final training  55/4999 loss: 1.7601 time 19.79s
0 Mon Mar 13 21:10:34 2023 Epoch: 56
Epoch 56/5000 0/2 loss: 1.8107 time 18.08s
Epoch 56/5000 1/2 loss: 1.7526 time 0.45s
Final training  56/4999 loss: 1.7526 time 18.54s
0 Mon Mar 13 21:10:52 2023 Epoch: 57
Epoch 57/5000 0/2 loss: 1.7921 time 19.43s
Epoch 57/5000 1/2 loss: 1.7647 time 0.45s
Final training  57/4999 loss: 1.7647 time 19.89s
0 Mon Mar 13 21:11:12 2023 Epoch: 58
Epoch 58/5000 0/2 loss: 1.7429 time 18.25s
Epoch 58/5000 1/2 loss: 1.7757 time 0.45s
Final training  58/4999 loss: 1.7757 time 18.71s
0 Mon Mar 13 21:11:31 2023 Epoch: 59
Epoch 59/5000 0/2 loss: 1.7167 time 20.44s
Epoch 59/5000 1/2 loss: 1.7832 time 0.45s
Final training  59/4999 loss: 1.7832 time 20.89s
0 Mon Mar 13 21:11:52 2023 Epoch: 60
Epoch 60/5000 0/2 loss: 1.7669 time 19.29s
Epoch 60/5000 1/2 loss: 1.7887 time 0.46s
Final training  60/4999 loss: 1.7887 time 19.75s
0 Mon Mar 13 21:12:11 2023 Epoch: 61
Epoch 61/5000 0/2 loss: 1.7264 time 19.44s
Epoch 61/5000 1/2 loss: 1.6934 time 0.46s
Final training  61/4999 loss: 1.6934 time 19.89s
0 Mon Mar 13 21:12:31 2023 Epoch: 62
Epoch 62/5000 0/2 loss: 1.6691 time 20.96s
Epoch 62/5000 1/2 loss: 1.7079 time 0.46s
Final training  62/4999 loss: 1.7079 time 21.41s
0 Mon Mar 13 21:12:53 2023 Epoch: 63
Epoch 63/5000 0/2 loss: 1.6753 time 20.80s
Epoch 63/5000 1/2 loss: 1.6494 time 0.46s
Final training  63/4999 loss: 1.6494 time 21.26s
0 Mon Mar 13 21:13:14 2023 Epoch: 64
Epoch 64/5000 0/2 loss: 1.6536 time 20.32s
Epoch 64/5000 1/2 loss: 1.6991 time 0.46s
Final training  64/4999 loss: 1.6991 time 20.77s
0 Mon Mar 13 21:13:35 2023 Epoch: 65
Epoch 65/5000 0/2 loss: 1.6218 time 20.18s
Epoch 65/5000 1/2 loss: 1.6413 time 0.46s
Final training  65/4999 loss: 1.6413 time 20.64s
0 Mon Mar 13 21:13:55 2023 Epoch: 66
Epoch 66/5000 0/2 loss: 1.6750 time 19.35s
Epoch 66/5000 1/2 loss: 1.6863 time 0.46s
Final training  66/4999 loss: 1.6863 time 19.81s
0 Mon Mar 13 21:14:15 2023 Epoch: 67
Epoch 67/5000 0/2 loss: 1.7351 time 19.22s
Epoch 67/5000 1/2 loss: 1.6858 time 0.46s
Final training  67/4999 loss: 1.6858 time 19.67s
0 Mon Mar 13 21:14:35 2023 Epoch: 68
Epoch 68/5000 0/2 loss: 1.6624 time 18.45s
Epoch 68/5000 1/2 loss: 1.6441 time 0.46s
Final training  68/4999 loss: 1.6441 time 18.91s
0 Mon Mar 13 21:14:54 2023 Epoch: 69
Epoch 69/5000 0/2 loss: 1.6200 time 18.69s
Epoch 69/5000 1/2 loss: 1.6210 time 0.46s
Final training  69/4999 loss: 1.6210 time 19.15s
0 Mon Mar 13 21:15:13 2023 Epoch: 70
Epoch 70/5000 0/2 loss: 1.6026 time 18.22s
Epoch 70/5000 1/2 loss: 1.6248 time 0.46s
Final training  70/4999 loss: 1.6248 time 18.68s
0 Mon Mar 13 21:15:32 2023 Epoch: 71
Epoch 71/5000 0/2 loss: 1.5514 time 18.24s
Epoch 71/5000 1/2 loss: 1.5854 time 0.46s
Final training  71/4999 loss: 1.5854 time 18.70s
0 Mon Mar 13 21:15:50 2023 Epoch: 72
Epoch 72/5000 0/2 loss: 1.5654 time 19.51s
Epoch 72/5000 1/2 loss: 1.6191 time 0.46s
Final training  72/4999 loss: 1.6191 time 19.97s
0 Mon Mar 13 21:16:10 2023 Epoch: 73
Epoch 73/5000 0/2 loss: 1.7178 time 19.15s
Epoch 73/5000 1/2 loss: 1.7197 time 0.46s
Final training  73/4999 loss: 1.7197 time 19.61s
0 Mon Mar 13 21:16:30 2023 Epoch: 74
Epoch 74/5000 0/2 loss: 1.6217 time 20.97s
Epoch 74/5000 1/2 loss: 1.7410 time 0.45s
Final training  74/4999 loss: 1.7410 time 21.42s
0 Mon Mar 13 21:16:51 2023 Epoch: 75
Epoch 75/5000 0/2 loss: 1.7677 time 19.99s
Epoch 75/5000 1/2 loss: 1.7009 time 0.46s
Final training  75/4999 loss: 1.7009 time 20.45s
0 Mon Mar 13 21:17:12 2023 Epoch: 76
Epoch 76/5000 0/2 loss: 1.5721 time 19.62s
Epoch 76/5000 1/2 loss: 1.5690 time 0.46s
Final training  76/4999 loss: 1.5690 time 20.08s
0 Mon Mar 13 21:17:32 2023 Epoch: 77
Epoch 77/5000 0/2 loss: 1.6412 time 19.38s
Epoch 77/5000 1/2 loss: 1.5356 time 0.46s
Final training  77/4999 loss: 1.5356 time 19.84s
0 Mon Mar 13 21:17:52 2023 Epoch: 78
Epoch 78/5000 0/2 loss: 1.5548 time 21.04s
Epoch 78/5000 1/2 loss: 1.5923 time 0.46s
Final training  78/4999 loss: 1.5923 time 21.50s
0 Mon Mar 13 21:18:13 2023 Epoch: 79
Epoch 79/5000 0/2 loss: 1.6011 time 20.43s
Epoch 79/5000 1/2 loss: 1.6673 time 0.46s
Final training  79/4999 loss: 1.6673 time 20.89s
0 Mon Mar 13 21:18:34 2023 Epoch: 80
Epoch 80/5000 0/2 loss: 1.5573 time 20.28s
Epoch 80/5000 1/2 loss: 1.5489 time 0.46s
Final training  80/4999 loss: 1.5489 time 20.74s
0 Mon Mar 13 21:18:55 2023 Epoch: 81
Epoch 81/5000 0/2 loss: 1.6533 time 18.37s
Epoch 81/5000 1/2 loss: 1.5917 time 0.46s
Final training  81/4999 loss: 1.5917 time 18.83s
0 Mon Mar 13 21:19:14 2023 Epoch: 82
Epoch 82/5000 0/2 loss: 1.6422 time 18.49s
Epoch 82/5000 1/2 loss: 1.7090 time 0.46s
Final training  82/4999 loss: 1.7090 time 18.95s
0 Mon Mar 13 21:19:33 2023 Epoch: 83
Epoch 83/5000 0/2 loss: 1.5238 time 19.12s
Epoch 83/5000 1/2 loss: 1.5790 time 0.45s
Final training  83/4999 loss: 1.5790 time 19.57s
0 Mon Mar 13 21:19:52 2023 Epoch: 84
Epoch 84/5000 0/2 loss: 1.5567 time 19.29s
Epoch 84/5000 1/2 loss: 1.5437 time 0.46s
Final training  84/4999 loss: 1.5437 time 19.75s
0 Mon Mar 13 21:20:12 2023 Epoch: 85
Epoch 85/5000 0/2 loss: 1.6435 time 19.13s
Epoch 85/5000 1/2 loss: 1.6435 time 0.46s
Final training  85/4999 loss: 1.6435 time 19.59s
0 Mon Mar 13 21:20:32 2023 Epoch: 86
Epoch 86/5000 0/2 loss: 1.5590 time 21.20s
Epoch 86/5000 1/2 loss: 1.5822 time 0.46s
Final training  86/4999 loss: 1.5822 time 21.66s
0 Mon Mar 13 21:20:53 2023 Epoch: 87
Epoch 87/5000 0/2 loss: 1.6365 time 20.31s
Epoch 87/5000 1/2 loss: 1.5424 time 0.46s
Final training  87/4999 loss: 1.5424 time 20.77s
0 Mon Mar 13 21:21:14 2023 Epoch: 88
Epoch 88/5000 0/2 loss: 1.7167 time 20.41s
Epoch 88/5000 1/2 loss: 1.6982 time 0.46s
Final training  88/4999 loss: 1.6982 time 20.86s
0 Mon Mar 13 21:21:35 2023 Epoch: 89
Epoch 89/5000 0/2 loss: 1.4731 time 20.37s
Epoch 89/5000 1/2 loss: 1.5282 time 0.46s
Final training  89/4999 loss: 1.5282 time 20.83s
0 Mon Mar 13 21:21:56 2023 Epoch: 90
Epoch 90/5000 0/2 loss: 1.5338 time 19.98s
Epoch 90/5000 1/2 loss: 1.5479 time 0.46s
Final training  90/4999 loss: 1.5479 time 20.44s
0 Mon Mar 13 21:22:16 2023 Epoch: 91
Epoch 91/5000 0/2 loss: 1.5584 time 20.03s
Epoch 91/5000 1/2 loss: 1.6020 time 0.46s
Final training  91/4999 loss: 1.6020 time 20.49s
0 Mon Mar 13 21:22:37 2023 Epoch: 92
Epoch 92/5000 0/2 loss: 1.5687 time 19.84s
Epoch 92/5000 1/2 loss: 1.5123 time 0.46s
Final training  92/4999 loss: 1.5123 time 20.30s
0 Mon Mar 13 21:22:57 2023 Epoch: 93
Epoch 93/5000 0/2 loss: 1.5313 time 18.55s
Epoch 93/5000 1/2 loss: 1.5897 time 0.46s
Final training  93/4999 loss: 1.5897 time 19.01s
0 Mon Mar 13 21:23:16 2023 Epoch: 94
Epoch 94/5000 0/2 loss: 1.4572 time 19.42s
Epoch 94/5000 1/2 loss: 1.5127 time 0.45s
Final training  94/4999 loss: 1.5127 time 19.87s
0 Mon Mar 13 21:23:36 2023 Epoch: 95
Epoch 95/5000 0/2 loss: 1.6503 time 20.59s
Epoch 95/5000 1/2 loss: 1.5814 time 0.45s
Final training  95/4999 loss: 1.5814 time 21.05s
0 Mon Mar 13 21:23:57 2023 Epoch: 96
Epoch 96/5000 0/2 loss: 1.5809 time 18.97s
Epoch 96/5000 1/2 loss: 1.5828 time 0.46s
Final training  96/4999 loss: 1.5828 time 19.44s
0 Mon Mar 13 21:24:16 2023 Epoch: 97
Epoch 97/5000 0/2 loss: 1.6158 time 18.96s
Epoch 97/5000 1/2 loss: 1.6565 time 0.46s
Final training  97/4999 loss: 1.6565 time 19.43s
0 Mon Mar 13 21:24:36 2023 Epoch: 98
Epoch 98/5000 0/2 loss: 1.6056 time 20.70s
Epoch 98/5000 1/2 loss: 1.6185 time 0.46s
Final training  98/4999 loss: 1.6185 time 21.16s
0 Mon Mar 13 21:24:57 2023 Epoch: 99
Epoch 99/5000 0/2 loss: 1.4911 time 19.68s
Epoch 99/5000 1/2 loss: 1.5187 time 0.46s
Final training  99/4999 loss: 1.5187 time 20.13s
Exception in thread Thread-1:
Traceback (most recent call last):
  File "/home/karimimonsefi.1/miniconda3/lib/python3.9/threading.py", line 980, in _bootstrap_inner
    self.run()
  File "/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/home/karimimonsefi.1/miniconda3/lib/python3.9/multiprocessing/queues.py", line 117, in get
    res = self._recv_bytes()
  File "/home/karimimonsefi.1/miniconda3/lib/python3.9/multiprocessing/connection.py", line 212, in recv_bytes
    self._check_closed()
  File "/home/karimimonsefi.1/miniconda3/lib/python3.9/multiprocessing/connection.py", line 136, in _check_closed
    raise OSError("handle is closed")
OSError: handle is closed
Traceback (most recent call last):
  File "/home/karimimonsefi.1/SSL_VAN/BTCV/main.py", line 257, in <module>
    main()
  File "/home/karimimonsefi.1/SSL_VAN/BTCV/main.py", line 97, in main
    mp.spawn(main_worker, nprocs=args.ngpus_per_node, args=(args,))
  File "/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 240, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 198, in start_processes
    while not context.join():
  File "/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 160, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File "/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 69, in _wrap
    fn(i, *args)
  File "/home/karimimonsefi.1/SSL_VAN/BTCV/main.py", line 239, in main_worker
    accuracy = run_training(
  File "/home/karimimonsefi.1/SSL_VAN/BTCV/trainer.py", line 169, in run_training
    val_avg_acc = val_epoch(
  File "/home/karimimonsefi.1/SSL_VAN/BTCV/trainer.py", line 86, in val_epoch
    acc_func(y_pred=val_output_convert, y=val_labels_convert)
  File "/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/monai/metrics/metric.py", line 329, in __call__
    ret = super().__call__(y_pred=y_pred, y=y)
  File "/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/monai/metrics/metric.py", line 68, in __call__
    return self._compute_list(y_pred, y)
  File "/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/monai/metrics/metric.py", line 90, in _compute_list
    ret = [self._compute_tensor(p.detach().unsqueeze(0), y_.detach().unsqueeze(0)) for p, y_ in zip(y_pred, y)]
  File "/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/monai/metrics/metric.py", line 90, in <listcomp>
    ret = [self._compute_tensor(p.detach().unsqueeze(0), y_.detach().unsqueeze(0)) for p, y_ in zip(y_pred, y)]
  File "/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/monai/metrics/meandice.py", line 81, in _compute_tensor
    return compute_meandice(
  File "/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/monai/metrics/meandice.py", line 136, in compute_meandice
    raise ValueError(f"y_pred and y should have same shapes, got {y_pred.shape} and {y.shape}.")
ValueError: y_pred and y should have same shapes, got torch.Size([1, 14, 320, 224, 256]) and torch.Size([1, 14, 314, 214, 234]).

