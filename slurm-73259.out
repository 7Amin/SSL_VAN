/var/spool/slurmd/job73259/slurm_script: line 11: cd: SSL_VAN: No such file or directory

----------------------------------------------------------------------------
  cuda:
----------------------------------------------------------------------------
     Versions:
        cuda/10.2
        cuda/11.0
        cuda/11.2
        cuda/11.3
        cuda/11.4
        cuda/11.5
        cuda/11.6
        cuda/11.7
        cuda/11.8
        cuda/12.0

----------------------------------------------------------------------------
  For detailed information about a specific "cuda" package (including how to load the modules) use the module's full name.
  Note that names that have a trailing (E) are extensions provided by other modules.
  For example:

     $ module spider cuda/12.0
----------------------------------------------------------------------------

 


CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.
To initialize your shell, run

    $ conda init <SHELL_NAME>

Currently supported shells are:
  - bash
  - fish
  - tcsh
  - xonsh
  - zsh
  - powershell

See 'conda init --help' for more information and options.

IMPORTANT: You may need to close and restart your shell after running 'conda init'.


/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/main.py:135: UserWarning: Found total gpus 2
  warnings.warn("Found total gpus {}".format(args.ngpus_per_node))
/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/main.py:155: UserWarning: 0 gpu 0
  warnings.warn(f"{args.rank} gpu {args.gpu}")
/home/karimimonsefi.1/SSL_VAN/MSD/main.py:157: UserWarning: Batch size is: 1 epochs 1000 and task is Task03_Liver
  warnings.warn(f"Batch size is: {args.batch_size} epochs {args.max_epochs} and task is {args.task}")
/home/karimimonsefi.1/SSL_VAN/MSD/main.py:155: UserWarning: 1 gpu 1
  warnings.warn(f"{args.rank} gpu {args.gpu}")
/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/monai/transforms/post/array.py:176: UserWarning: `to_onehot=True/False` is deprecated, please use `to_onehot=num_classes` instead.
  warnings.warn("`to_onehot=True/False` is deprecated, please use `to_onehot=num_classes` instead.")
/home/karimimonsefi.1/SSL_VAN/MSD/main.py:190: UserWarning: Total parameters count 30745326
  warnings.warn(f"Total parameters count {pytorch_total_params}")
/home/karimimonsefi.1/SSL_VAN/MSD/main.py:193: UserWarning: Total args.checkpoint True
  warnings.warn(f"Total args.checkpoint {args.checkpoint}")
/home/karimimonsefi.1/SSL_VAN/commons/util.py:6: UserWarning:  base_url is 64-128-256-512_3-4-6-3_8-8-4-4_vae_inferer_valid_loader_nnUNet_Task03_Liver
  warnings.warn(f" base_url is {base_url}")
/home/karimimonsefi.1/SSL_VAN/commons/util.py:8: UserWarning:  output_url 1 is ./runs/MSD_new/test_log/output_False_False
  warnings.warn(f" output_url 1 is {output_url}")
/home/karimimonsefi.1/SSL_VAN/commons/util.py:9: UserWarning:  exists 1 is True
  warnings.warn(f" exists 1 is {os.path.exists(output_url)}")
/home/karimimonsefi.1/SSL_VAN/commons/util.py:13: UserWarning:  output_url 2 is ./runs/MSD_new/test_log/output_False_False/64-128-256-512_3-4-6-3_8-8-4-4_vae_inferer_valid_loader_nnUNet_Task03_Liver
  warnings.warn(f" output_url 2 is {output_url}")
/home/karimimonsefi.1/SSL_VAN/commons/util.py:14: UserWarning:  exists 2 is False
  warnings.warn(f" exists 2 is {os.path.exists(output_url)}")
/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/monai/transforms/post/array.py:176: UserWarning: `to_onehot=True/False` is deprecated, please use `to_onehot=num_classes` instead.
  warnings.warn("`to_onehot=True/False` is deprecated, please use `to_onehot=num_classes` instead.")
/home/karimimonsefi.1/SSL_VAN/MSD/main.py:190: UserWarning: Total parameters count 30745326
  warnings.warn(f"Total parameters count {pytorch_total_params}")
/home/karimimonsefi.1/SSL_VAN/MSD/main.py:193: UserWarning: Total args.checkpoint True
  warnings.warn(f"Total args.checkpoint {args.checkpoint}")
/home/karimimonsefi.1/SSL_VAN/commons/util.py:20: UserWarning:  Best url model is 64-128-256-512_3-4-6-3_8-8-4-4_vae_inferer_valid_loader_nnUNet_Task03_Liver__best.pt, final model url is 64-128-256-512_3-4-6-3_8-8-4-4_vae_inferer_valid_loader_nnUNet_Task03_Liver__final.pt
  warnings.warn(f" Best url model is {args.best_model_url}, final model url is {args.final_model_url}")
/home/karimimonsefi.1/SSL_VAN/commons/util.py:6: UserWarning:  base_url is 64-128-256-512_3-4-6-3_8-8-4-4_vae_inferer_valid_loader_nnUNet_Task03_Liver
  warnings.warn(f" base_url is {base_url}")
/home/karimimonsefi.1/SSL_VAN/commons/util.py:8: UserWarning:  output_url 1 is ./runs/MSD_new/test_log/output_False_False
  warnings.warn(f" output_url 1 is {output_url}")
/home/karimimonsefi.1/SSL_VAN/MSD/main.py:207: UserWarning: => loaded checkpoint 'True' (epoch 0) (bestacc 0.0)
  warnings.warn("=> loaded checkpoint '{}' (epoch {}) (bestacc {})".format(
/home/karimimonsefi.1/SSL_VAN/commons/util.py:9: UserWarning:  exists 1 is True
  warnings.warn(f" exists 1 is {os.path.exists(output_url)}")
/home/karimimonsefi.1/SSL_VAN/commons/util.py:13: UserWarning:  output_url 2 is ./runs/MSD_new/test_log/output_False_False/64-128-256-512_3-4-6-3_8-8-4-4_vae_inferer_valid_loader_nnUNet_Task03_Liver
  warnings.warn(f" output_url 2 is {output_url}")
/home/karimimonsefi.1/SSL_VAN/commons/util.py:14: UserWarning:  exists 2 is True
  warnings.warn(f" exists 2 is {os.path.exists(output_url)}")
/home/karimimonsefi.1/SSL_VAN/commons/util.py:20: UserWarning:  Best url model is 64-128-256-512_3-4-6-3_8-8-4-4_vae_inferer_valid_loader_nnUNet_Task03_Liver__best.pt, final model url is 64-128-256-512_3-4-6-3_8-8-4-4_vae_inferer_valid_loader_nnUNet_Task03_Liver__final.pt
  warnings.warn(f" Best url model is {args.best_model_url}, final model url is {args.final_model_url}")
/home/karimimonsefi.1/SSL_VAN/MSD/main.py:207: UserWarning: => loaded checkpoint 'True' (epoch 0) (bestacc 0.0)
  warnings.warn("=> loaded checkpoint '{}' (epoch {}) (bestacc {})".format(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:139: UserWarning: Writing Tensorboard logs to ./runs/MSD_new/test_log
  warnings.warn(f"Writing Tensorboard logs to {args.logdir}")
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:147: UserWarning: 0  Thu Aug 10 12:49:08 2023  Epoch: 0
  warnings.warn(f"{args.rank}  {time.ctime()}  Epoch: {epoch}")
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:147: UserWarning: 1  Thu Aug 10 12:49:08 2023  Epoch: 0
  warnings.warn(f"{args.rank}  {time.ctime()}  Epoch: {epoch}")
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:29: UserWarning: input size torch.Size([6, 1, 96, 96, 96])
  warnings.warn("input size {}".format(data.shape))
[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:29: UserWarning: input size torch.Size([6, 1, 96, 96, 96])
  warnings.warn("input size {}".format(data.shape))
[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 0/54  loss: 4.0868  time 40.36s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 1/54  loss: 4.0732  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 2/54  loss: 4.0821  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 3/54  loss: 4.0880  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 4/54  loss: 4.0890  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 5/54  loss: 4.0910  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 6/54  loss: 4.0930  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 7/54  loss: 4.0948  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 8/54  loss: 4.0978  time 6.05s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 9/54  loss: 4.0984  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 10/54  loss: 4.0982  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 11/54  loss: 4.0990  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 12/54  loss: 4.0992  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 13/54  loss: 4.0979  time 7.01s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 14/54  loss: 4.0975  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 15/54  loss: 4.0995  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 16/54  loss: 4.0980  time 12.33s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 17/54  loss: 4.0980  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 18/54  loss: 4.0996  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 19/54  loss: 4.0993  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 20/54  loss: 4.0985  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 21/54  loss: 4.0984  time 3.01s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 22/54  loss: 4.0965  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 23/54  loss: 4.0970  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 24/54  loss: 4.0972  time 10.88s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 25/54  loss: 4.0966  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 26/54  loss: 4.0965  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 27/54  loss: 4.0964  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 28/54  loss: 4.0967  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 29/54  loss: 4.0966  time 2.95s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 30/54  loss: 4.0964  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 31/54  loss: 4.0956  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 32/54  loss: 4.0952  time 12.49s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 33/54  loss: 4.0955  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 34/54  loss: 4.0956  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 35/54  loss: 4.0961  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 36/54  loss: 4.0964  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 37/54  loss: 4.0964  time 1.13s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 38/54  loss: 4.0963  time 3.35s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 39/54  loss: 4.0958  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 40/54  loss: 4.0957  time 9.48s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 41/54  loss: 4.0967  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 42/54  loss: 4.0964  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 43/54  loss: 4.0964  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 44/54  loss: 4.0961  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 45/54  loss: 4.0961  time 1.66s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 46/54  loss: 4.0959  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 47/54  loss: 4.0962  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 48/54  loss: 4.0964  time 4.46s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 49/54  loss: 4.0965  time 0.21s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 50/54  loss: 4.0967  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 51/54  loss: 4.0974  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 52/54  loss: 4.0976  time 0.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:51: UserWarning: Epoch 0/1000 53/54  loss: 4.0974  time 7.63s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:153: UserWarning: Final training  0/999  loss: 4.0974  time 130.82s
  warnings.warn("Final training  {}/{}  loss: {:.4f}  time {:.2f}s".format(epoch, args.max_epochs - 1,
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:147: UserWarning: 1  Thu Aug 10 12:51:18 2023  Epoch: 1
  warnings.warn(f"{args.rank}  {time.ctime()}  Epoch: {epoch}")
/home/karimimonsefi.1/SSL_VAN/MSD/trainer.py:147: UserWarning: 0  Thu Aug 10 12:51:18 2023  Epoch: 1
  warnings.warn(f"{args.rank}  {time.ctime()}  Epoch: {epoch}")
