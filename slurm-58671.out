
----------------------------------------------------------------------------
  cuda:
----------------------------------------------------------------------------
     Versions:
        cuda/10.2
        cuda/11.0
        cuda/11.2
        cuda/11.3
        cuda/11.4
        cuda/11.5
        cuda/11.6
        cuda/11.7
        cuda/11.8
        cuda/12.0

----------------------------------------------------------------------------
  For detailed information about a specific "cuda" package (including how to load the modules) use the module's full name.
  Note that names that have a trailing (E) are extensions provided by other modules.
  For example:

     $ module spider cuda/12.0
----------------------------------------------------------------------------

 


CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.
To initialize your shell, run

    $ conda init <SHELL_NAME>

Currently supported shells are:
  - bash
  - fish
  - tcsh
  - xonsh
  - zsh
  - powershell

See 'conda init --help' for more information and options.

IMPORTANT: You may need to close and restart your shell after running 'conda init'.


/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/main.py:109: UserWarning: Found total gpus 2
  warnings.warn("Found total gpus {}".format(args.ngpus_per_node))
/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/main.py:136: UserWarning: 0 gpu 0
  warnings.warn(f"{args.rank} gpu {args.gpu}")
/home/karimimonsefi.1/SSL_VAN/pretrain/main.py:136: UserWarning: 1 gpu 1
  warnings.warn(f"{args.rank} gpu {args.gpu}")
/home/karimimonsefi.1/SSL_VAN/pretrain/main.py:138: UserWarning: Batch size is: 4 epochs 15000
  warnings.warn(f"Batch size is: {args.batch_size} epochs {args.max_epochs}")
/home/karimimonsefi.1/SSL_VAN/pretrain/main.py:145: UserWarning: Total parameters count 36285642
  warnings.warn(f"Total parameters count {pytorch_total_params}")
/home/karimimonsefi.1/SSL_VAN/pretrain/main.py:148: UserWarning: Total args.checkpoint True
  warnings.warn(f"Total args.checkpoint {args.checkpoint}")
/home/karimimonsefi.1/SSL_VAN/pretrain/main.py:157: UserWarning:  Best url model is pre_train_64-128-256-512_3-4-6-3_8-8-4-4_vae_inferer_valid_loader_PREVANV4__best.pt, final model url is pre_train_64-128-256-512_3-4-6-3_8-8-4-4_vae_inferer_valid_loader_PREVANV4__final.pt
  warnings.warn(f" Best url model is {args.best_model_url}, final model url is {args.final_model_url}")
/home/karimimonsefi.1/SSL_VAN/pretrain/main.py:145: UserWarning: Total parameters count 36285642
  warnings.warn(f"Total parameters count {pytorch_total_params}")
/home/karimimonsefi.1/SSL_VAN/pretrain/main.py:148: UserWarning: Total args.checkpoint True
  warnings.warn(f"Total args.checkpoint {args.checkpoint}")
/home/karimimonsefi.1/SSL_VAN/pretrain/main.py:157: UserWarning:  Best url model is pre_train_64-128-256-512_3-4-6-3_8-8-4-4_vae_inferer_valid_loader_PREVANV4__best.pt, final model url is pre_train_64-128-256-512_3-4-6-3_8-8-4-4_vae_inferer_valid_loader_PREVANV4__final.pt
  warnings.warn(f" Best url model is {args.best_model_url}, final model url is {args.final_model_url}")
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:109: UserWarning: Writing Tensorboard logs to ./runs/pre_train_1/test_log
  warnings.warn(f"Writing Tensorboard logs to {args.logdir}")
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:119: UserWarning: 0  Sat Jun 10 14:18:18 2023  Epoch: 0
  warnings.warn(f"{args.rank}  {time.ctime()}  Epoch: {epoch}")
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:119: UserWarning: 1  Sat Jun 10 14:18:18 2023  Epoch: 0
  warnings.warn(f"{args.rank}  {time.ctime()}  Epoch: {epoch}")
Dataset 1 LUNA16: OK number of data: 842
Dataset 2 Covid 19: OK number of data: 722
Dataset 3 HNSCC: OK number of data: 954
Dataset 4 TCIA Colon: OK number of data: 1532
Dataset 5 TCIA LIDC: OK number of data: 450
Dataset all training: number of data: 4500
loader is ready
Dataset 1 LUNA16: OK number of data: 842
Dataset 2 Covid 19: OK number of data: 722
Dataset 3 HNSCC: OK number of data: 954
Dataset 4 TCIA Colon: OK number of data: 1532
Dataset 5 TCIA LIDC: OK number of data: 450
Dataset all training: number of data: 4500
loader is ready
tensor([[[[[1.0000, 1.0000, 1.0000,  ..., 0.9790, 0.9770, 0.9425],
           [1.0000, 1.0000, 0.9970,  ..., 0.9700, 0.9985, 1.0000],
           [1.0000, 1.0000, 1.0000,  ..., 0.9745, 0.9340, 0.9695],
           ...,
           [0.5440, 0.5540, 0.5580,  ..., 0.5140, 0.5375, 0.5555],
           [0.5435, 0.5525, 0.5685,  ..., 0.5355, 0.5110, 0.5325],
           [0.5490, 0.5485, 0.5555,  ..., 0.5675, 0.5395, 0.5275]],

          [[1.0000, 1.0000, 1.0000,  ..., 0.9550, 0.9400, 0.9570],
           [1.0000, 0.9950, 0.9735,  ..., 1.0000, 0.9955, 0.9650],
           [1.0000, 1.0000, 1.0000,  ..., 0.9495, 0.9745, 0.9750],
           ...,
           [0.5600, 0.5610, 0.5490,  ..., 0.5460, 0.5320, 0.5635],
           [0.5540, 0.5670, 0.5535,  ..., 0.5395, 0.5160, 0.5045],
           [0.5740, 0.5710, 0.5645,  ..., 0.5490, 0.5460, 0.5280]],

          [[1.0000, 1.0000, 1.0000,  ..., 0.9520, 0.9435, 0.9680],
           [1.0000, 0.9880, 0.9725,  ..., 0.9625, 0.9475, 0.9280],
           [1.0000, 1.0000, 1.0000,  ..., 0.9625, 0.9835, 0.9845],
           ...,
           [0.5555, 0.5715, 0.5560,  ..., 0.5640, 0.5345, 0.5510],
           [0.5445, 0.5620, 0.5530,  ..., 0.5400, 0.5365, 0.5395],
           [0.5630, 0.5570, 0.5505,  ..., 0.5310, 0.5370, 0.5340]],

          ...,

          [[1.0000, 1.0000, 1.0000,  ..., 0.9590, 0.9860, 0.9700],
           [1.0000, 1.0000, 0.9910,  ..., 0.9605, 0.9725, 0.9770],
           [1.0000, 0.9960, 0.9910,  ..., 0.9905, 0.9805, 0.9755],
           ...,
           [0.9770, 1.0000, 1.0000,  ..., 0.5605, 0.5565, 0.5305],
           [0.9395, 0.9575, 0.9605,  ..., 0.5350, 0.5505, 0.5325],
           [0.9725, 0.9615, 0.9810,  ..., 0.5265, 0.5500, 0.5520]],

          [[1.0000, 1.0000, 1.0000,  ..., 0.9445, 0.9625, 0.9795],
           [1.0000, 1.0000, 1.0000,  ..., 0.9610, 0.9560, 0.9760],
           [1.0000, 1.0000, 1.0000,  ..., 0.9835, 0.9695, 0.9600],
           ...,
           [0.9430, 0.9520, 0.9710,  ..., 0.5240, 0.5420, 0.5470],
           [0.9385, 0.9230, 0.9450,  ..., 0.5305, 0.5240, 0.5435],
           [1.0000, 0.9695, 0.9565,  ..., 0.5310, 0.5290, 0.5235]],

          [[1.0000, 1.0000, 0.9825,  ..., 0.9480, 0.9630, 0.9745],
           [1.0000, 1.0000, 1.0000,  ..., 0.9690, 0.9570, 0.9485],
           [1.0000, 1.0000, 1.0000,  ..., 0.9905, 0.9730, 0.9555],
           ...,
           [0.9665, 0.9690, 0.9535,  ..., 0.5155, 0.5180, 0.5210],
           [0.9430, 0.9630, 0.9715,  ..., 0.5310, 0.5355, 0.5370],
           [0.9405, 0.9585, 0.9530,  ..., 0.5140, 0.5245, 0.5240]]]],



        [[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           ...,
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           ...,
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           ...,
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

          ...,

          [[0.0000, 0.0000, 0.0000,  ..., 0.5115, 0.5210, 0.5280],
           [0.0000, 0.0000, 0.0000,  ..., 0.5085, 0.5165, 0.5125],
           [0.0000, 0.0000, 0.0000,  ..., 0.5055, 0.5280, 0.5125],
           ...,
           [0.5075, 0.5015, 0.5095,  ..., 0.5000, 0.5070, 0.5210],
           [0.5060, 0.5000, 0.5000,  ..., 0.5020, 0.5035, 0.5155],
           [0.5065, 0.5190, 0.5050,  ..., 0.5155, 0.5075, 0.5035]],

          [[0.0000, 0.0000, 0.0000,  ..., 0.5105, 0.5110, 0.5100],
           [0.0000, 0.0000, 0.0000,  ..., 0.5190, 0.5065, 0.5080],
           [0.0000, 0.0000, 0.0000,  ..., 0.5185, 0.5175, 0.5090],
           ...,
           [0.5220, 0.5275, 0.5115,  ..., 0.5140, 0.5045, 0.5115],
           [0.5115, 0.5270, 0.5275,  ..., 0.5120, 0.5065, 0.5080],
           [0.5155, 0.5155, 0.5110,  ..., 0.5120, 0.5145, 0.5180]],

          [[0.0000, 0.0000, 0.0000,  ..., 0.5065, 0.5225, 0.5105],
           [0.0000, 0.0000, 0.0000,  ..., 0.5030, 0.5195, 0.5325],
           [0.0000, 0.0000, 0.0000,  ..., 0.5150, 0.5205, 0.5340],
           ...,
           [0.5055, 0.5310, 0.5210,  ..., 0.5125, 0.5285, 0.5115],
           [0.5000, 0.5165, 0.5315,  ..., 0.5195, 0.5190, 0.5000],
           [0.5050, 0.5000, 0.5150,  ..., 0.5125, 0.5110, 0.5055]]]],



        [[[[0.5040, 0.5000, 0.5050,  ..., 1.0000, 1.0000, 1.0000],
           [0.5735, 0.5650, 0.5275,  ..., 1.0000, 1.0000, 1.0000],
           [0.5195, 0.5360, 0.5245,  ..., 1.0000, 1.0000, 1.0000],
           ...,
           [0.9735, 0.9455, 0.9845,  ..., 1.0000, 1.0000, 1.0000],
           [0.9465, 0.9340, 0.9590,  ..., 1.0000, 1.0000, 1.0000],
           [0.9255, 0.9785, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],

          [[0.5075, 0.5185, 0.5320,  ..., 1.0000, 1.0000, 1.0000],
           [0.5000, 0.5190, 0.5015,  ..., 1.0000, 1.0000, 1.0000],
           [0.5665, 0.5635, 0.5495,  ..., 0.9740, 1.0000, 1.0000],
           ...,
           [0.9470, 0.9550, 0.9625,  ..., 1.0000, 1.0000, 1.0000],
           [0.9110, 0.9035, 0.9550,  ..., 1.0000, 1.0000, 1.0000],
           [0.9260, 0.9515, 0.9835,  ..., 1.0000, 1.0000, 1.0000]],

          [[0.5425, 0.5290, 0.5300,  ..., 1.0000, 1.0000, 1.0000],
           [0.5060, 0.5125, 0.5130,  ..., 1.0000, 1.0000, 1.0000],
           [0.5070, 0.5000, 0.5000,  ..., 1.0000, 1.0000, 0.9965],
           ...,
           [0.9405, 0.9580, 0.9830,  ..., 1.0000, 1.0000, 1.0000],
           [0.9920, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
           [0.9615, 0.9585, 0.9545,  ..., 1.0000, 1.0000, 1.0000]],

          ...,

          [[0.9925, 0.9815, 0.9595,  ..., 0.9500, 0.9565, 1.0000],
           [0.9515, 1.0000, 1.0000,  ..., 0.9620, 1.0000, 1.0000],
           [0.8250, 0.9030, 0.9625,  ..., 0.9990, 0.9930, 0.9910],
           ...,
           [0.9570, 0.9680, 0.9435,  ..., 0.5095, 0.5100, 0.5065],
           [0.9285, 0.9405, 0.9435,  ..., 0.5050, 0.5000, 0.5110],
           [0.9350, 0.9605, 0.9725,  ..., 0.5190, 0.5190, 0.5180]],

          [[0.9675, 0.9910, 1.0000,  ..., 0.9205, 0.9485, 1.0000],
           [0.8820, 0.9285, 0.9660,  ..., 0.9825, 0.9955, 1.0000],
           [0.7255, 0.8250, 0.8945,  ..., 0.9775, 1.0000, 1.0000],
           ...,
           [0.9665, 0.9745, 0.9700,  ..., 0.5155, 0.5180, 0.5225],
           [0.9610, 0.9745, 0.9580,  ..., 0.5365, 0.5100, 0.5405],
           [0.9825, 0.9815, 0.9430,  ..., 0.5410, 0.5145, 0.5450]],

          [[0.9365, 0.9875, 1.0000,  ..., 0.9610, 1.0000, 1.0000],
           [0.7765, 0.8360, 0.9405,  ..., 0.9185, 0.9755, 1.0000],
           [0.6385, 0.7015, 0.7830,  ..., 0.9690, 0.9770, 1.0000],
           ...,
           [0.9595, 0.9705, 0.9560,  ..., 0.5135, 0.5205, 0.5000],
           [0.9575, 0.9715, 0.9550,  ..., 0.5270, 0.5140, 0.5000],
           [0.9605, 0.9620, 0.9425,  ..., 0.5160, 0.5235, 0.5185]]]],



        ...,



        [[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           ...,
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           ...,
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           ...,
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

          ...,

          [[0.9640, 0.9615, 0.9640,  ..., 0.9635, 0.9655, 0.9590],
           [0.9830, 0.9780, 0.9740,  ..., 0.9675, 0.9660, 0.9610],
           [1.0000, 1.0000, 1.0000,  ..., 0.9580, 0.9595, 0.9575],
           ...,
           [0.6100, 0.6350, 0.6500,  ..., 1.0000, 1.0000, 1.0000],
           [0.5975, 0.6330, 0.6315,  ..., 1.0000, 1.0000, 1.0000],
           [0.5840, 0.6045, 0.5890,  ..., 1.0000, 1.0000, 1.0000]],

          [[0.9705, 0.9710, 0.9720,  ..., 0.9700, 0.9730, 0.9735],
           [0.9805, 0.9835, 0.9845,  ..., 0.9805, 0.9805, 0.9790],
           [1.0000, 1.0000, 1.0000,  ..., 0.9895, 0.9895, 0.9865],
           ...,
           [0.5770, 0.6045, 0.6235,  ..., 1.0000, 1.0000, 1.0000],
           [0.5635, 0.5870, 0.5880,  ..., 1.0000, 1.0000, 1.0000],
           [0.5620, 0.5715, 0.5685,  ..., 1.0000, 1.0000, 1.0000]],

          [[0.9855, 0.9860, 0.9865,  ..., 0.9700, 0.9770, 0.9865],
           [0.9790, 0.9800, 0.9815,  ..., 1.0000, 1.0000, 1.0000],
           [0.9885, 0.9910, 0.9915,  ..., 1.0000, 1.0000, 1.0000],
           ...,
           [0.5555, 0.5610, 0.5720,  ..., 1.0000, 1.0000, 1.0000],
           [0.5515, 0.5530, 0.5555,  ..., 1.0000, 1.0000, 1.0000],
           [0.5615, 0.5600, 0.5585,  ..., 1.0000, 1.0000, 1.0000]]]],



        [[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           ...,
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

          [[0.5150, 0.5080, 0.5085,  ..., 0.5165, 0.5120, 0.5075],
           [0.5115, 0.5115, 0.5125,  ..., 0.5085, 0.5125, 0.5120],
           [0.5115, 0.5175, 0.5150,  ..., 0.5075, 0.5195, 0.5225],
           ...,
           [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
           [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
           [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],

          [[0.5175, 0.5140, 0.5125,  ..., 0.5115, 0.5050, 0.5090],
           [0.5130, 0.5155, 0.5125,  ..., 0.5085, 0.5115, 0.5145],
           [0.5120, 0.5155, 0.5120,  ..., 0.5160, 0.5180, 0.5200],
           ...,
           [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
           [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
           [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],

          ...,

          [[0.5605, 0.5600, 0.5550,  ..., 0.5775, 0.5800, 0.5770],
           [0.5615, 0.5645, 0.5565,  ..., 0.5875, 0.5830, 0.5745],
           [0.5635, 0.5720, 0.5635,  ..., 0.5780, 0.5715, 0.5620],
           ...,
           [1.0000, 1.0000, 1.0000,  ..., 0.5575, 0.5650, 0.5705],
           [1.0000, 1.0000, 1.0000,  ..., 0.5685, 0.5820, 0.5855],
           [1.0000, 1.0000, 1.0000,  ..., 0.5870, 0.6165, 0.6275]],

          [[0.5670, 0.5590, 0.5550,  ..., 0.5630, 0.5605, 0.5570],
           [0.5685, 0.5590, 0.5560,  ..., 0.5665, 0.5615, 0.5595],
           [0.5745, 0.5715, 0.5680,  ..., 0.5600, 0.5595, 0.5635],
           ...,
           [1.0000, 1.0000, 1.0000,  ..., 0.5595, 0.5645, 0.5745],
           [1.0000, 1.0000, 1.0000,  ..., 0.5600, 0.5670, 0.5960],
           [1.0000, 1.0000, 1.0000,  ..., 0.5620, 0.5755, 0.6185]],

          [[0.5565, 0.5505, 0.5555,  ..., 0.5735, 0.5670, 0.5650],
           [0.5630, 0.5565, 0.5600,  ..., 0.5710, 0.5650, 0.5740],
           [0.5735, 0.5730, 0.5840,  ..., 0.5635, 0.5735, 0.5850],
           ...,
           [1.0000, 1.0000, 1.0000,  ..., 0.5585, 0.5635, 0.5730],
           [1.0000, 1.0000, 1.0000,  ..., 0.5595, 0.5650, 0.5815],
           [1.0000, 1.0000, 1.0000,  ..., 0.5590, 0.5640, 0.5870]]]],



        [[[[0.5170, 0.5105, 0.5115,  ..., 0.5135, 0.5145, 0.5120],
           [0.5170, 0.5120, 0.5125,  ..., 0.5110, 0.5115, 0.5100],
           [0.5125, 0.5135, 0.5145,  ..., 0.5120, 0.5090, 0.5135],
           ...,
           [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
           [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
           [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],

          [[0.5185, 0.5105, 0.5115,  ..., 0.5085, 0.5140, 0.5130],
           [0.5115, 0.5110, 0.5145,  ..., 0.5125, 0.5150, 0.5120],
           [0.5075, 0.5105, 0.5145,  ..., 0.5175, 0.5145, 0.5125],
           ...,
           [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
           [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
           [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],

          [[0.5155, 0.5135, 0.5115,  ..., 0.5090, 0.5160, 0.5175],
           [0.5105, 0.5110, 0.5175,  ..., 0.5120, 0.5170, 0.5145],
           [0.5060, 0.5080, 0.5175,  ..., 0.5150, 0.5185, 0.5150],
           ...,
           [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
           [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
           [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],

          ...,

          [[0.9955, 1.0000, 1.0000,  ..., 0.9900, 0.9960, 0.9815],
           [1.0000, 0.9985, 0.9835,  ..., 0.9645, 0.9715, 0.9660],
           [0.9780, 0.9630, 0.9555,  ..., 0.9670, 0.9745, 0.9715],
           ...,
           [1.0000, 1.0000, 1.0000,  ..., 0.9550, 0.9645, 0.9680],
           [1.0000, 1.0000, 1.0000,  ..., 0.9615, 0.9750, 0.9785],
           [1.0000, 1.0000, 1.0000,  ..., 0.9735, 0.9805, 0.9805]],

          [[1.0000, 1.0000, 1.0000,  ..., 0.9805, 0.9770, 0.9605],
           [1.0000, 0.9805, 0.9780,  ..., 0.9675, 0.9680, 0.9585],
           [0.9690, 0.9545, 0.9555,  ..., 0.9765, 0.9785, 0.9705],
           ...,
           [1.0000, 1.0000, 1.0000,  ..., 0.9700, 0.9700, 0.9590],
           [1.0000, 1.0000, 1.0000,  ..., 0.9735, 0.9845, 0.9710],
           [1.0000, 1.0000, 1.0000,  ..., 0.9800, 0.9870, 0.9690]],

          [[1.0000, 1.0000, 1.0000,  ..., 0.9715, 0.9735, 0.9605],
           [0.9915, 0.9735, 0.9695,  ..., 0.9640, 0.9720, 0.9680],
           [0.9615, 0.9505, 0.9520,  ..., 0.9720, 0.9785, 0.9740],
           ...,
           [1.0000, 1.0000, 1.0000,  ..., 0.9760, 0.9750, 0.9735],
           [1.0000, 1.0000, 1.0000,  ..., 0.9655, 0.9800, 0.9835],
           [1.0000, 1.0000, 1.0000,  ..., 0.9640, 0.9825, 0.9810]]]]])
torch.Size([16, 1, 96, 96, 96])
Traceback (most recent call last):
  File "/home/karimimonsefi.1/SSL_VAN/pretrain/main.py", line 215, in <module>
    main()
  File "/home/karimimonsefi.1/SSL_VAN/pretrain/main.py", line 111, in main
    mp.spawn(main_worker, nprocs=args.ngpus_per_node, args=(args,))
  File "/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 240, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 198, in start_processes
    while not context.join():
  File "/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 160, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 1 terminated with the following error:
Traceback (most recent call last):
  File "/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 69, in _wrap
    fn(i, *args)
  File "/home/karimimonsefi.1/SSL_VAN/pretrain/main.py", line 197, in main_worker
    loss_value = run_training(
  File "/home/karimimonsefi.1/SSL_VAN/pretrain/training.py", line 121, in run_training
    train_loss = train_epoch(
  File "/home/karimimonsefi.1/SSL_VAN/pretrain/training.py", line 47, in train_epoch
    target = get_target(data, clusters, embed_dim, embed_number_values)
  File "/home/karimimonsefi.1/SSL_VAN/pretrain/training.py", line 19, in get_target
    data_numpy = data.detach.numpy()
AttributeError: 'builtin_function_or_method' object has no attribute 'numpy'

