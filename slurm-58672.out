
----------------------------------------------------------------------------
  cuda:
----------------------------------------------------------------------------
     Versions:
        cuda/10.2
        cuda/11.0
        cuda/11.2
        cuda/11.3
        cuda/11.4
        cuda/11.5
        cuda/11.6
        cuda/11.7
        cuda/11.8
        cuda/12.0

----------------------------------------------------------------------------
  For detailed information about a specific "cuda" package (including how to load the modules) use the module's full name.
  Note that names that have a trailing (E) are extensions provided by other modules.
  For example:

     $ module spider cuda/12.0
----------------------------------------------------------------------------

 


CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.
To initialize your shell, run

    $ conda init <SHELL_NAME>

Currently supported shells are:
  - bash
  - fish
  - tcsh
  - xonsh
  - zsh
  - powershell

See 'conda init --help' for more information and options.

IMPORTANT: You may need to close and restart your shell after running 'conda init'.


/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/main.py:109: UserWarning: Found total gpus 2
  warnings.warn("Found total gpus {}".format(args.ngpus_per_node))
/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/main.py:136: UserWarning: 0 gpu 0
  warnings.warn(f"{args.rank} gpu {args.gpu}")
/home/karimimonsefi.1/SSL_VAN/pretrain/main.py:138: UserWarning: Batch size is: 4 epochs 15000
  warnings.warn(f"Batch size is: {args.batch_size} epochs {args.max_epochs}")
/home/karimimonsefi.1/SSL_VAN/pretrain/main.py:136: UserWarning: 1 gpu 1
  warnings.warn(f"{args.rank} gpu {args.gpu}")
/home/karimimonsefi.1/SSL_VAN/pretrain/main.py:145: UserWarning: Total parameters count 36285642
  warnings.warn(f"Total parameters count {pytorch_total_params}")
/home/karimimonsefi.1/SSL_VAN/pretrain/main.py:145: UserWarning: Total parameters count 36285642
  warnings.warn(f"Total parameters count {pytorch_total_params}")
/home/karimimonsefi.1/SSL_VAN/pretrain/main.py:148: UserWarning: Total args.checkpoint True
  warnings.warn(f"Total args.checkpoint {args.checkpoint}")
/home/karimimonsefi.1/SSL_VAN/pretrain/main.py:148: UserWarning: Total args.checkpoint True
  warnings.warn(f"Total args.checkpoint {args.checkpoint}")
/home/karimimonsefi.1/SSL_VAN/pretrain/main.py:157: UserWarning:  Best url model is pre_train_64-128-256-512_3-4-6-3_8-8-4-4_vae_inferer_valid_loader_PREVANV4__best.pt, final model url is pre_train_64-128-256-512_3-4-6-3_8-8-4-4_vae_inferer_valid_loader_PREVANV4__final.pt
  warnings.warn(f" Best url model is {args.best_model_url}, final model url is {args.final_model_url}")
/home/karimimonsefi.1/SSL_VAN/pretrain/main.py:157: UserWarning:  Best url model is pre_train_64-128-256-512_3-4-6-3_8-8-4-4_vae_inferer_valid_loader_PREVANV4__best.pt, final model url is pre_train_64-128-256-512_3-4-6-3_8-8-4-4_vae_inferer_valid_loader_PREVANV4__final.pt
  warnings.warn(f" Best url model is {args.best_model_url}, final model url is {args.final_model_url}")
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:109: UserWarning: Writing Tensorboard logs to ./runs/pre_train_1/test_log
  warnings.warn(f"Writing Tensorboard logs to {args.logdir}")
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:119: UserWarning: 0  Sat Jun 10 14:21:02 2023  Epoch: 0
  warnings.warn(f"{args.rank}  {time.ctime()}  Epoch: {epoch}")
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:119: UserWarning: 1  Sat Jun 10 14:21:02 2023  Epoch: 0
  warnings.warn(f"{args.rank}  {time.ctime()}  Epoch: {epoch}")
Dataset 1 LUNA16: OK number of data: 842
Dataset 2 Covid 19: OK number of data: 722
Dataset 3 HNSCC: OK number of data: 954
Dataset 4 TCIA Colon: OK number of data: 1532
Dataset 5 TCIA LIDC: OK number of data: 450
Dataset all training: number of data: 4500
loader is ready
Dataset 1 LUNA16: OK number of data: 842
Dataset 2 Covid 19: OK number of data: 722
Dataset 3 HNSCC: OK number of data: 954
Dataset 4 TCIA Colon: OK number of data: 1532
Dataset 5 TCIA LIDC: OK number of data: 450
Dataset all training: number of data: 4500
loader is ready
tensor([[[[[0.5000, 0.5095, 0.5230,  ..., 0.5000, 0.5200, 0.5105],
           [0.5055, 0.5125, 0.5200,  ..., 0.5000, 0.5250, 0.5150],
           [0.5210, 0.5115, 0.5055,  ..., 0.5110, 0.5215, 0.5235],
           ...,
           [0.9885, 0.9630, 0.9730,  ..., 0.9870, 0.9890, 0.9480],
           [1.0000, 0.9770, 0.9820,  ..., 0.9745, 0.9590, 0.9425],
           [1.0000, 0.9780, 0.9780,  ..., 0.9510, 0.9255, 0.9360]],

          [[0.5135, 0.5135, 0.5210,  ..., 0.5000, 0.5285, 0.5195],
           [0.5170, 0.5155, 0.5250,  ..., 0.5065, 0.5260, 0.5150],
           [0.5205, 0.5055, 0.5185,  ..., 0.5050, 0.5325, 0.5170],
           ...,
           [0.9940, 0.9630, 0.9770,  ..., 0.9725, 0.9840, 0.9720],
           [0.9810, 0.9815, 0.9835,  ..., 1.0000, 0.9685, 0.9615],
           [0.9685, 1.0000, 1.0000,  ..., 0.9785, 0.9360, 0.9570]],

          [[0.5040, 0.5045, 0.5250,  ..., 0.5230, 0.5060, 0.5060],
           [0.5075, 0.5100, 0.5175,  ..., 0.5225, 0.5130, 0.5085],
           [0.5200, 0.5145, 0.5000,  ..., 0.5195, 0.5145, 0.5050],
           ...,
           [0.9675, 0.9360, 0.9565,  ..., 0.9600, 0.9565, 0.9740],
           [0.9830, 0.9650, 0.9540,  ..., 0.9890, 0.9730, 0.9685],
           [0.9650, 0.9830, 0.9815,  ..., 1.0000, 0.9765, 0.9475]],

          ...,

          [[0.5185, 0.5000, 0.5115,  ..., 0.5250, 0.5135, 0.5240],
           [0.5215, 0.5030, 0.5000,  ..., 0.5175, 0.5075, 0.5180],
           [0.5145, 0.5160, 0.5000,  ..., 0.5000, 0.5075, 0.5165],
           ...,
           [0.9655, 0.9750, 0.9915,  ..., 0.9845, 0.9840, 0.9885],
           [0.9810, 0.9800, 0.9785,  ..., 0.9660, 0.9655, 0.9595],
           [0.9820, 0.9665, 0.9695,  ..., 0.9510, 0.9565, 0.9705]],

          [[0.5095, 0.5045, 0.5175,  ..., 0.5085, 0.5105, 0.5240],
           [0.5095, 0.5000, 0.5045,  ..., 0.5125, 0.5185, 0.5245],
           [0.5215, 0.5100, 0.5055,  ..., 0.5095, 0.5225, 0.5195],
           ...,
           [0.9610, 0.9570, 0.9750,  ..., 0.9865, 1.0000, 0.9900],
           [0.9605, 0.9595, 0.9480,  ..., 0.9880, 0.9830, 0.9440],
           [0.9660, 0.9830, 0.9820,  ..., 0.9720, 0.9425, 0.9125]],

          [[0.5015, 0.5025, 0.5100,  ..., 0.5035, 0.5105, 0.5060],
           [0.5010, 0.5000, 0.5050,  ..., 0.5100, 0.5105, 0.5075],
           [0.5130, 0.5000, 0.5060,  ..., 0.5100, 0.5115, 0.5190],
           ...,
           [0.9755, 0.9520, 0.9725,  ..., 0.9635, 0.9785, 1.0000],
           [0.9675, 0.9540, 0.9305,  ..., 0.9535, 0.9660, 0.9915],
           [0.9815, 1.0000, 0.9780,  ..., 0.9495, 0.9410, 0.9495]]]],



        [[[[1.0000, 1.0000, 0.9950,  ..., 0.9770, 0.9775, 0.9550],
           [1.0000, 1.0000, 0.9845,  ..., 1.0000, 1.0000, 0.9735],
           [1.0000, 1.0000, 1.0000,  ..., 0.9880, 0.9890, 0.9825],
           ...,
           [0.9475, 0.9380, 0.9565,  ..., 1.0000, 1.0000, 0.9680],
           [0.9525, 0.9310, 0.9450,  ..., 1.0000, 0.9845, 0.9470],
           [0.9720, 0.9545, 0.9360,  ..., 1.0000, 0.9530, 0.9350]],

          [[1.0000, 1.0000, 1.0000,  ..., 0.9770, 0.9725, 0.9725],
           [1.0000, 1.0000, 1.0000,  ..., 0.9940, 0.9590, 0.9330],
           [1.0000, 1.0000, 1.0000,  ..., 0.9665, 0.9780, 0.9690],
           ...,
           [0.9730, 0.9535, 0.9405,  ..., 1.0000, 1.0000, 0.9840],
           [0.9705, 0.9735, 0.9765,  ..., 1.0000, 0.9910, 0.9345],
           [0.9805, 0.9890, 0.9725,  ..., 1.0000, 0.9945, 0.9680]],

          [[0.9955, 1.0000, 1.0000,  ..., 0.9650, 0.9845, 0.9905],
           [0.9830, 0.9910, 0.9710,  ..., 0.9980, 0.9810, 0.9635],
           [1.0000, 1.0000, 1.0000,  ..., 0.9595, 0.9555, 0.9645],
           ...,
           [0.9740, 0.9615, 0.9440,  ..., 1.0000, 1.0000, 1.0000],
           [0.9605, 0.9840, 0.9890,  ..., 1.0000, 1.0000, 0.9785],
           [0.9575, 0.9775, 1.0000,  ..., 0.9905, 0.9930, 0.9695]],

          ...,

          [[1.0000, 1.0000, 1.0000,  ..., 0.9835, 0.9525, 0.9145],
           [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9935],
           [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
           ...,
           [0.5140, 0.5180, 0.5395,  ..., 0.9385, 0.9860, 1.0000],
           [0.5000, 0.5030, 0.5340,  ..., 0.9525, 0.9965, 1.0000],
           [0.5045, 0.5195, 0.5370,  ..., 0.9895, 1.0000, 1.0000]],

          [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 0.9500, 0.9240],
           [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
           [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
           ...,
           [0.5185, 0.5185, 0.5320,  ..., 0.9625, 0.9940, 1.0000],
           [0.5245, 0.5190, 0.5235,  ..., 0.9575, 1.0000, 0.9890],
           [0.5305, 0.5305, 0.5090,  ..., 0.9845, 1.0000, 1.0000]],

          [[1.0000, 1.0000, 1.0000,  ..., 0.9955, 1.0000, 1.0000],
           [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
           [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
           ...,
           [0.5415, 0.5225, 0.5035,  ..., 0.9095, 1.0000, 1.0000],
           [0.5230, 0.5220, 0.5130,  ..., 0.9325, 1.0000, 1.0000],
           [0.5345, 0.5245, 0.5065,  ..., 1.0000, 1.0000, 1.0000]]]],



        [[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           ...,
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

          [[0.5595, 0.5615, 0.5480,  ..., 0.5300, 0.5400, 0.5420],
           [0.5420, 0.5560, 0.5530,  ..., 0.5405, 0.5465, 0.5505],
           [0.5360, 0.5590, 0.5640,  ..., 0.5615, 0.5520, 0.5390],
           ...,
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

          [[0.5325, 0.5470, 0.5375,  ..., 0.5225, 0.5395, 0.5495],
           [0.5455, 0.5735, 0.5535,  ..., 0.5485, 0.5445, 0.5425],
           [0.5435, 0.5760, 0.5740,  ..., 0.5470, 0.5560, 0.5515],
           ...,
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

          ...,

          [[0.5500, 0.5275, 0.5520,  ..., 0.5520, 0.5760, 0.5465],
           [0.5570, 0.5260, 0.5355,  ..., 0.5060, 0.5345, 0.5420],
           [0.5590, 0.5290, 0.5235,  ..., 0.5360, 0.5280, 0.5380],
           ...,
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

          [[0.5235, 0.5150, 0.5545,  ..., 0.5385, 0.5475, 0.5430],
           [0.5355, 0.5215, 0.5290,  ..., 0.5285, 0.5255, 0.5065],
           [0.5750, 0.5525, 0.5415,  ..., 0.5190, 0.5345, 0.5520],
           ...,
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

          [[0.5575, 0.5340, 0.5215,  ..., 0.5550, 0.5155, 0.5080],
           [0.5685, 0.5670, 0.5480,  ..., 0.5465, 0.5485, 0.5165],
           [0.5520, 0.5505, 0.5585,  ..., 0.5315, 0.5490, 0.5380],
           ...,
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]],



        ...,



        [[[[0.8675, 0.8740, 0.8770,  ..., 0.8225, 0.8675, 0.8985],
           [0.6940, 0.7140, 0.7355,  ..., 0.6865, 0.7145, 0.7350],
           [0.5725, 0.5820, 0.5940,  ..., 0.6975, 0.7050, 0.7190],
           ...,
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

          [[0.8660, 0.8595, 0.8535,  ..., 0.9350, 0.9600, 0.9720],
           [0.6900, 0.7105, 0.7320,  ..., 0.7700, 0.7935, 0.8065],
           [0.5595, 0.5735, 0.5885,  ..., 0.7010, 0.7145, 0.7235],
           ...,
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

          [[0.8475, 0.8480, 0.8525,  ..., 1.0000, 1.0000, 1.0000],
           [0.6740, 0.7045, 0.7280,  ..., 0.8540, 0.8725, 0.8750],
           [0.5585, 0.5705, 0.5830,  ..., 0.7275, 0.7430, 0.7470],
           ...,
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

          ...,

          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           ...,
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           ...,
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           ...,
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]],



        [[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           ...,
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           ...,
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           ...,
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

          ...,

          [[0.5205, 0.5180, 0.5075,  ..., 0.5480, 0.5510, 0.5530],
           [0.5140, 0.5195, 0.5140,  ..., 0.5225, 0.5280, 0.5340],
           [0.5135, 0.5140, 0.5180,  ..., 0.5215, 0.5240, 0.5220],
           ...,
           [0.5905, 0.5860, 0.5925,  ..., 0.5710, 0.5535, 0.5505],
           [0.5940, 0.5855, 0.5955,  ..., 0.5765, 0.5615, 0.5555],
           [0.6075, 0.5950, 0.5890,  ..., 0.5740, 0.5620, 0.5590]],

          [[0.5145, 0.5170, 0.5110,  ..., 0.5275, 0.5310, 0.5360],
           [0.5090, 0.5180, 0.5200,  ..., 0.5165, 0.5180, 0.5200],
           [0.5140, 0.5145, 0.5230,  ..., 0.5225, 0.5215, 0.5185],
           ...,
           [0.6445, 0.6540, 0.6415,  ..., 0.5800, 0.5630, 0.5575],
           [0.6685, 0.6840, 0.6880,  ..., 0.5765, 0.5730, 0.5665],
           [0.6935, 0.7210, 0.7315,  ..., 0.5765, 0.5865, 0.5905]],

          [[0.5135, 0.5170, 0.5185,  ..., 0.5145, 0.5200, 0.5245],
           [0.5130, 0.5175, 0.5240,  ..., 0.5140, 0.5145, 0.5150],
           [0.5195, 0.5200, 0.5225,  ..., 0.5170, 0.5135, 0.5135],
           ...,
           [0.6645, 0.6960, 0.6740,  ..., 0.5840, 0.5730, 0.5830],
           [0.6795, 0.7175, 0.7205,  ..., 0.6125, 0.6355, 0.6745],
           [0.6670, 0.7105, 0.7480,  ..., 0.6630, 0.7290, 0.7875]]]],



        [[[[0.9725, 0.9655, 0.9610,  ..., 0.5695, 0.5755, 0.5790],
           [0.9450, 0.9500, 0.9560,  ..., 0.5775, 0.5745, 0.5765],
           [0.9525, 0.9460, 0.9485,  ..., 0.5710, 0.5665, 0.5695],
           ...,
           [1.0000, 1.0000, 1.0000,  ..., 0.7110, 0.6600, 0.6330],
           [1.0000, 1.0000, 1.0000,  ..., 0.9295, 0.8200, 0.7260],
           [1.0000, 0.9995, 0.9890,  ..., 1.0000, 1.0000, 0.9495]],

          [[0.9845, 0.9780, 0.9760,  ..., 0.5770, 0.5865, 0.5950],
           [0.9515, 0.9525, 0.9610,  ..., 0.5870, 0.5895, 0.5865],
           [0.9525, 0.9520, 0.9540,  ..., 0.5775, 0.5750, 0.5750],
           ...,
           [1.0000, 1.0000, 1.0000,  ..., 0.5880, 0.5865, 0.5845],
           [1.0000, 1.0000, 1.0000,  ..., 0.6155, 0.5855, 0.5640],
           [1.0000, 1.0000, 1.0000,  ..., 0.6875, 0.6300, 0.5940]],

          [[0.9785, 0.9725, 0.9765,  ..., 0.5755, 0.5835, 0.5960],
           [0.9635, 0.9615, 0.9760,  ..., 0.5910, 0.5935, 0.5840],
           [0.9810, 0.9785, 0.9725,  ..., 0.5945, 0.5855, 0.5815],
           ...,
           [1.0000, 1.0000, 1.0000,  ..., 0.6075, 0.6050, 0.6105],
           [1.0000, 1.0000, 1.0000,  ..., 0.6285, 0.6090, 0.5880],
           [1.0000, 1.0000, 1.0000,  ..., 0.5965, 0.5830, 0.5685]],

          ...,

          [[1.0000, 1.0000, 1.0000,  ..., 0.5775, 0.5905, 0.5895],
           [1.0000, 1.0000, 1.0000,  ..., 0.5760, 0.5905, 0.5995],
           [1.0000, 1.0000, 1.0000,  ..., 0.6055, 0.6060, 0.6175],
           ...,
           [1.0000, 1.0000, 1.0000,  ..., 0.5785, 0.5790, 0.5735],
           [1.0000, 1.0000, 1.0000,  ..., 0.5755, 0.5790, 0.5765],
           [1.0000, 1.0000, 1.0000,  ..., 0.5845, 0.5820, 0.5770]],

          [[1.0000, 1.0000, 1.0000,  ..., 0.6020, 0.5945, 0.5830],
           [1.0000, 1.0000, 1.0000,  ..., 0.6150, 0.5985, 0.5720],
           [1.0000, 1.0000, 1.0000,  ..., 0.6025, 0.5845, 0.5750],
           ...,
           [1.0000, 1.0000, 1.0000,  ..., 0.5940, 0.5950, 0.5940],
           [1.0000, 1.0000, 1.0000,  ..., 0.5895, 0.5890, 0.5835],
           [1.0000, 1.0000, 1.0000,  ..., 0.5900, 0.5870, 0.5800]],

          [[1.0000, 1.0000, 1.0000,  ..., 0.5645, 0.5535, 0.5870],
           [1.0000, 1.0000, 1.0000,  ..., 0.5790, 0.5555, 0.5670],
           [1.0000, 1.0000, 1.0000,  ..., 0.5755, 0.5565, 0.5585],
           ...,
           [1.0000, 1.0000, 1.0000,  ..., 0.7400, 0.7845, 0.7885],
           [1.0000, 1.0000, 1.0000,  ..., 0.7510, 0.7695, 0.7405],
           [1.0000, 1.0000, 1.0000,  ..., 0.7440, 0.7360, 0.6785]]]]])
torch.Size([16, 1, 96, 96, 96])
Traceback (most recent call last):
  File "/home/karimimonsefi.1/SSL_VAN/pretrain/main.py", line 215, in <module>
    main()
  File "/home/karimimonsefi.1/SSL_VAN/pretrain/main.py", line 111, in main
    mp.spawn(main_worker, nprocs=args.ngpus_per_node, args=(args,))
  File "/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 240, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 198, in start_processes
    while not context.join():
  File "/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 160, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 1 terminated with the following error:
Traceback (most recent call last):
  File "/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 69, in _wrap
    fn(i, *args)
  File "/home/karimimonsefi.1/SSL_VAN/pretrain/main.py", line 197, in main_worker
    loss_value = run_training(
  File "/home/karimimonsefi.1/SSL_VAN/pretrain/training.py", line 121, in run_training
    train_loss = train_epoch(
  File "/home/karimimonsefi.1/SSL_VAN/pretrain/training.py", line 47, in train_epoch
    target = get_target(data, clusters, embed_dim, embed_number_values)
  File "/home/karimimonsefi.1/SSL_VAN/pretrain/training.py", line 20, in get_target
    b, z, x, y = data.shape
ValueError: too many values to unpack (expected 4)

