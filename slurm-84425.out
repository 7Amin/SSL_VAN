NODELIST=a100-[11-12]
MASTER_ADDR=a100-11

CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.
To initialize your shell, run

    $ conda init <SHELL_NAME>

Currently supported shells are:
  - bash
  - fish
  - tcsh
  - xonsh
  - zsh
  - powershell

See 'conda init --help' for more information and options.

IMPORTANT: You may need to close and restart your shell after running 'conda init'.


/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/monai/transforms/post/array.py:176: UserWarning: `to_onehot=True/False` is deprecated, please use `to_onehot=num_classes` instead.
  warnings.warn("`to_onehot=True/False` is deprecated, please use `to_onehot=num_classes` instead.")
/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/monai/transforms/post/array.py:176: UserWarning: `to_onehot=True/False` is deprecated, please use `to_onehot=num_classes` instead.
  warnings.warn("`to_onehot=True/False` is deprecated, please use `to_onehot=num_classes` instead.")
/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/monai/transforms/post/array.py:176: UserWarning: `to_onehot=True/False` is deprecated, please use `to_onehot=num_classes` instead.
  warnings.warn("`to_onehot=True/False` is deprecated, please use `to_onehot=num_classes` instead.")
/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/monai/transforms/post/array.py:176: UserWarning: `to_onehot=True/False` is deprecated, please use `to_onehot=num_classes` instead.
  warnings.warn("`to_onehot=True/False` is deprecated, please use `to_onehot=num_classes` instead.")
World Size: 2
World Size: 2
input_list/dataset_BTCV_List.json
Total parameters count 94231722
Total args.checkpoint True
 base_url is 128-128-512-512_4-4-5-5_4-4-4-4_vae_inferer_valid_loader_VANV4121double
 output_url 1 is ./runs/BTCV/test_log/output_False_False
 exists 1 is True
 output_url 2 is ./runs/BTCV/test_log/output_False_False/128-128-512-512_4-4-5-5_4-4-4-4_vae_inferer_valid_loader_VANV4121double
 exists 2 is True
 Best url model is 128-128-512-512_4-4-5-5_4-4-4-4_vae_inferer_valid_loader_VANV4121double__best.pt, final model url is 128-128-512-512_4-4-5-5_4-4-4-4_vae_inferer_valid_loader_VANV4121double__final.pt
=> loaded checkpoint 'True' (epoch 3189) (bestacc 0.7658345699310303)
[GPU 0] Epochs 3189, BatchSize: 1 | Steps: 6
World Size: 2
World Size: 2
/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.
  warnings.warn(
/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.
  warnings.warn(
/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.
  warnings.warn(
/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.
  warnings.warn(
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.460902214050293 | Loss: 1.460902214050293
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.4797270894050598 | Loss: 1.4985519647598267
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.4753353993097942 | Loss: 1.4665520191192627
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.424719363451004 | Loss: 1.2728712558746338
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.479387640953064 | Loss: 1.6980607509613037
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.4900786479314168 | Loss: 1.5435336828231812
Epochs is 3189 | Loss is 1.4900786479314168
Start Val
Val 3189/5000 0/1  acc [0.75651485] | 0.756514847278595  time 14.07s
Final validation  3189/4999  acc: 0.7565  time 14.07s
Saving checkpoint ./runs/BTCV/test_log/128-128-512-512_4-4-5-5_4-4-4-4_vae_inferer_valid_loader_VANV4121double__final.pt
[GPU 0] Epochs 3190, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.4766532182693481 | Loss: 1.4766532182693481
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.5867486596107483 | Loss: 1.6968441009521484
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.5326382716496785 | Loss: 1.424417495727539
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.4687325656414032 | Loss: 1.2770154476165771
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.45062096118927 | Loss: 1.3781745433807373
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.445728321870168 | Loss: 1.4212651252746582
Epochs is 3190 | Loss is 1.445728321870168
[GPU 0] Epochs 3191, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.2773733139038086 | Loss: 1.2773733139038086
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.3661648035049438 | Loss: 1.454956293106079
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.3493363857269287 | Loss: 1.3156795501708984
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.3627590537071228 | Loss: 1.403027057647705
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.4270402431488036 | Loss: 1.6841650009155273
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.457355797290802 | Loss: 1.6089335680007935
Epochs is 3191 | Loss is 1.457355797290802
[GPU 0] Epochs 3192, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.5925054550170898 | Loss: 1.5925054550170898
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.5324477553367615 | Loss: 1.472390055656433
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.566901723543803 | Loss: 1.6358096599578857
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.5463193655014038 | Loss: 1.4845722913742065
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.541171908378601 | Loss: 1.5205820798873901
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.5290425022443135 | Loss: 1.468395471572876
Epochs is 3192 | Loss is 1.5290425022443135
[GPU 0] Epochs 3193, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.393712043762207 | Loss: 1.393712043762207
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.390423059463501 | Loss: 1.387134075164795
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.37788192431132 | Loss: 1.352799654006958
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.3672564327716827 | Loss: 1.335379958152771
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.3577462434768677 | Loss: 1.3197054862976074
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.3807165225346882 | Loss: 1.4955679178237915
Epochs is 3193 | Loss is 1.3807165225346882
[GPU 0] Epochs 3194, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.1475121974945068 | Loss: 1.1475121974945068
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.2667404413223267 | Loss: 1.3859686851501465
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.2953096230824788 | Loss: 1.3524479866027832
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.2953665554523468 | Loss: 1.2955373525619507
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.3585517644882201 | Loss: 1.6112926006317139
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.3647342125574748 | Loss: 1.3956464529037476
Epochs is 3194 | Loss is 1.3647342125574748
[GPU 0] Epochs 3195, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.3702095746994019 | Loss: 1.3702095746994019
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.3610735535621643 | Loss: 1.3519375324249268
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.3528371651967366 | Loss: 1.3363643884658813
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.3865013122558594 | Loss: 1.4874937534332275
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.38361496925354 | Loss: 1.3720695972442627
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.4245866537094116 | Loss: 1.6294450759887695
Epochs is 3195 | Loss is 1.4245866537094116
[GPU 0] Epochs 3196, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.3730558156967163 | Loss: 1.3730558156967163
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.4521281719207764 | Loss: 1.5312005281448364
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.3501554330190022 | Loss: 1.146209955215454
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.3442872166633606 | Loss: 1.3266825675964355
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.373267650604248 | Loss: 1.4891893863677979
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.3925765752792358 | Loss: 1.4891211986541748
Epochs is 3196 | Loss is 1.3925765752792358
[GPU 0] Epochs 3197, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.3414314985275269 | Loss: 1.3414314985275269
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.4436100125312805 | Loss: 1.5457885265350342
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.461355487505595 | Loss: 1.4968464374542236
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.4393738806247711 | Loss: 1.3734290599822998
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.4333872079849244 | Loss: 1.409440517425537
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.4421493212382 | Loss: 1.4859598875045776
Epochs is 3197 | Loss is 1.4421493212382
[GPU 0] Epochs 3198, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.6465330123901367 | Loss: 1.6465330123901367
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.6506245136260986 | Loss: 1.6547160148620605
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.6436207294464111 | Loss: 1.6296131610870361
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.5469542741775513 | Loss: 1.2569549083709717
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.5275060892105103 | Loss: 1.4497133493423462
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.487619658311208 | Loss: 1.2881875038146973
Epochs is 3198 | Loss is 1.487619658311208
[GPU 0] Epochs 3199, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.5088119506835938 | Loss: 1.5088119506835938
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.5049508810043335 | Loss: 1.5010898113250732
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.586064100265503 | Loss: 1.7482905387878418
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.5284890234470367 | Loss: 1.3557637929916382
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.5400486230850219 | Loss: 1.586287021636963
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.5534281134605408 | Loss: 1.6203255653381348
Epochs is 3199 | Loss is 1.5534281134605408
Start Val
Val 3199/5000 0/1  acc [0.7647848] | 0.7647848129272461  time 8.67s
Final validation  3199/4999  acc: 0.7648  time 8.67s
Saving checkpoint ./runs/BTCV/test_log/128-128-512-512_4-4-5-5_4-4-4-4_vae_inferer_valid_loader_VANV4121double__final.pt
[GPU 0] Epochs 3200, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.518384337425232 | Loss: 1.518384337425232
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.5308207869529724 | Loss: 1.543257236480713
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.5299644867579143 | Loss: 1.5282518863677979
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.483277052640915 | Loss: 1.343214750289917
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.521509623527527 | Loss: 1.6744399070739746
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.4932254354159038 | Loss: 1.351804494857788
Epochs is 3200 | Loss is 1.4932254354159038
[GPU 0] Epochs 3201, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.338758945465088 | Loss: 1.338758945465088
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.2876461744308472 | Loss: 1.2365334033966064
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.32158096631368 | Loss: 1.3894505500793457
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.3297388553619385 | Loss: 1.3542125225067139
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.310050106048584 | Loss: 1.231295108795166
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.3546969493230183 | Loss: 1.5779311656951904
Epochs is 3201 | Loss is 1.3546969493230183
[GPU 0] Epochs 3202, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.3520894050598145 | Loss: 1.3520894050598145
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.4222878217697144 | Loss: 1.4924862384796143
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.423357645670573 | Loss: 1.42549729347229
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.446994125843048 | Loss: 1.5179035663604736
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.4370800495147704 | Loss: 1.3974237442016602
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.4209883014361064 | Loss: 1.3405295610427856
Epochs is 3202 | Loss is 1.4209883014361064
[GPU 0] Epochs 3203, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.2951948642730713 | Loss: 1.2951948642730713
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.428163230419159 | Loss: 1.5611315965652466
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.478946050008138 | Loss: 1.5805116891860962
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.4144492745399475 | Loss: 1.220958948135376
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.4222099304199218 | Loss: 1.4532525539398193
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.4286491870880127 | Loss: 1.4608454704284668
Epochs is 3203 | Loss is 1.4286491870880127
[GPU 0] Epochs 3204, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.288221836090088 | Loss: 1.288221836090088
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.371384859085083 | Loss: 1.4545478820800781
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.4205977121988933 | Loss: 1.5190234184265137
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.437552273273468 | Loss: 1.4884159564971924
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.4556359767913818 | Loss: 1.527970790863037
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.4654638171195984 | Loss: 1.5146030187606812
Epochs is 3204 | Loss is 1.4654638171195984
[GPU 0] Epochs 3205, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.504287600517273 | Loss: 1.504287600517273
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.422040581703186 | Loss: 1.3397935628890991
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.464382489522298 | Loss: 1.5490663051605225
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.4261587262153625 | Loss: 1.3114874362945557
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.3987619400024414 | Loss: 1.2891747951507568
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.422800342241923 | Loss: 1.542992353439331
Epochs is 3205 | Loss is 1.422800342241923
[GPU 0] Epochs 3206, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.667677402496338 | Loss: 1.667677402496338
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.6408400535583496 | Loss: 1.6140027046203613
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.5634939670562744 | Loss: 1.408801794052124
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.498391717672348 | Loss: 1.3030849695205688
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.5359703063964845 | Loss: 1.6862846612930298
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.5029857953389485 | Loss: 1.3380632400512695
Epochs is 3206 | Loss is 1.5029857953389485
[GPU 0] Epochs 3207, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.3662245273590088 | Loss: 1.3662245273590088
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.4638359546661377 | Loss: 1.5614473819732666
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.4686898390452068 | Loss: 1.4783976078033447
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.4457309246063232 | Loss: 1.3768541812896729
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.4238038063049316 | Loss: 1.3360953330993652
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.4428020517031352 | Loss: 1.5377932786941528
Epochs is 3207 | Loss is 1.4428020517031352
[GPU 0] Epochs 3208, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.2129521369934082 | Loss: 1.2129521369934082
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.3648810386657715 | Loss: 1.5168099403381348
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.4040014743804932 | Loss: 1.4822423458099365
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.351160705089569 | Loss: 1.1926383972167969
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.3743353843688966 | Loss: 1.467034101486206
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.3598346312840779 | Loss: 1.2873308658599854
Epochs is 3208 | Loss is 1.3598346312840779
[GPU 0] Epochs 3209, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.4808437824249268 | Loss: 1.4808437824249268
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.4931498765945435 | Loss: 1.5054559707641602
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.4296724796295166 | Loss: 1.302717685699463
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.3893492817878723 | Loss: 1.2683796882629395
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.4285258769989013 | Loss: 1.5852322578430176
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.4275081555048625 | Loss: 1.422419548034668
Epochs is 3209 | Loss is 1.4275081555048625
Start Val
Val 3209/5000 0/1  acc [0.7696913] | 0.7696912884712219  time 8.71s
Final validation  3209/4999  acc: 0.7697  time 8.71s
new best (0.765835 --> 0.769691). 
Saving checkpoint ./runs/BTCV/test_log/128-128-512-512_4-4-5-5_4-4-4-4_vae_inferer_valid_loader_VANV4121double__final.pt
Copying to best model new best model!!!!
[GPU 0] Epochs 3210, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.6020393371582031 | Loss: 1.6020393371582031
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.505213439464569 | Loss: 1.408387541770935
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.4381929636001587 | Loss: 1.304152011871338
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.3949994444847107 | Loss: 1.2654188871383667
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.424333643913269 | Loss: 1.5416704416275024
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.4365986386934917 | Loss: 1.4979236125946045
Epochs is 3210 | Loss is 1.4365986386934917
[GPU 0] Epochs 3211, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.2734841108322144 | Loss: 1.2734841108322144
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.4127850532531738 | Loss: 1.5520859956741333
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.386993686358134 | Loss: 1.3354109525680542
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.432692974805832 | Loss: 1.5697908401489258
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.4435179948806762 | Loss: 1.4868180751800537
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.4787888725598652 | Loss: 1.6551432609558105
Epochs is 3211 | Loss is 1.4787888725598652
[GPU 0] Epochs 3212, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.3102279901504517 | Loss: 1.3102279901504517
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.3902031183242798 | Loss: 1.470178246498108
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.418847680091858 | Loss: 1.4761368036270142
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.392119586467743 | Loss: 1.311935305595398
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.355492925643921 | Loss: 1.2089862823486328
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.3936299085617065 | Loss: 1.5843148231506348
Epochs is 3212 | Loss is 1.3936299085617065
[GPU 0] Epochs 3213, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.3380411863327026 | Loss: 1.3380411863327026
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.4315405488014221 | Loss: 1.5250399112701416
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.3885653416315715 | Loss: 1.3026149272918701
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.4334215819835663 | Loss: 1.5679903030395508
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.455043864250183 | Loss: 1.5415329933166504
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.438189446926117 | Loss: 1.3539173603057861
Epochs is 3213 | Loss is 1.438189446926117
[GPU 0] Epochs 3214, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.6342581510543823 | Loss: 1.6342581510543823
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.5841125845909119 | Loss: 1.5339670181274414
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.5147464672724407 | Loss: 1.376014232635498
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.4407907128334045 | Loss: 1.2189234495162964
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.4325216293334961 | Loss: 1.3994452953338623
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.4221631288528442 | Loss: 1.370370626449585
Epochs is 3214 | Loss is 1.4221631288528442
[GPU 0] Epochs 3215, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.3430354595184326 | Loss: 1.3430354595184326
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.4150298833847046 | Loss: 1.4870243072509766
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.456255356470744 | Loss: 1.5387063026428223
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.4283016324043274 | Loss: 1.3444404602050781
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.485856056213379 | Loss: 1.716073751449585
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.4618947903315227 | Loss: 1.3420884609222412
Epochs is 3215 | Loss is 1.4618947903315227
[GPU 0] Epochs 3216, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.437098741531372 | Loss: 1.437098741531372
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.4766772985458374 | Loss: 1.5162558555603027
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.4037342071533203 | Loss: 1.2578480243682861
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.4014979898929596 | Loss: 1.3947893381118774
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.4497677564620972 | Loss: 1.6428468227386475
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.4497331778208415 | Loss: 1.449560284614563
Epochs is 3216 | Loss is 1.4497331778208415
[GPU 0] Epochs 3217, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.482835292816162 | Loss: 1.482835292816162
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.459317684173584 | Loss: 1.4358000755310059
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.4784862597783406 | Loss: 1.516823410987854
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.4520260393619537 | Loss: 1.372645378112793
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.4506482839584351 | Loss: 1.4451372623443604
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.4272220730781555 | Loss: 1.3100910186767578
Epochs is 3217 | Loss is 1.4272220730781555
[GPU 0] Epochs 3218, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.4179714918136597 | Loss: 1.4179714918136597
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.4198957085609436 | Loss: 1.4218199253082275
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.4882073799769084 | Loss: 1.624830722808838
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.49156054854393 | Loss: 1.5016200542449951
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.4821688890457154 | Loss: 1.4446022510528564
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.505334198474884 | Loss: 1.6211607456207275
Epochs is 3218 | Loss is 1.505334198474884
[GPU 0] Epochs 3219, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.4981764554977417 | Loss: 1.4981764554977417
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.4270208477973938 | Loss: 1.355865240097046
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.4851339260737102 | Loss: 1.6013600826263428
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.4779624342918396 | Loss: 1.456447958946228
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.4234105110168458 | Loss: 1.2052028179168701
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.44584459066391 | Loss: 1.558014988899231
Epochs is 3219 | Loss is 1.44584459066391
Start Val
Val 3219/5000 0/1  acc [0.76127654] | 0.7612765431404114  time 8.70s
Final validation  3219/4999  acc: 0.7613  time 8.70s
Saving checkpoint ./runs/BTCV/test_log/128-128-512-512_4-4-5-5_4-4-4-4_vae_inferer_valid_loader_VANV4121double__final.pt
[GPU 0] Epochs 3220, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.4011310338974 | Loss: 1.4011310338974
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.4521272778511047 | Loss: 1.5031235218048096
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.4137617746988933 | Loss: 1.3370307683944702
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.4433535933494568 | Loss: 1.5321290493011475
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.4635295867919922 | Loss: 1.5442335605621338
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.4741572141647339 | Loss: 1.5272953510284424
Epochs is 3220 | Loss is 1.4741572141647339
[GPU 0] Epochs 3221, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.4750999212265015 | Loss: 1.4750999212265015
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.4036459922790527 | Loss: 1.332192063331604
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.4134116967519124 | Loss: 1.4329431056976318
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.4104288816452026 | Loss: 1.4014804363250732
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.4278262853622437 | Loss: 1.4974159002304077
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.4012784759203594 | Loss: 1.2685394287109375
Epochs is 3221 | Loss is 1.4012784759203594
[GPU 0] Epochs 3222, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.4380024671554565 | Loss: 1.4380024671554565
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.3778207898139954 | Loss: 1.3176391124725342
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.3585962057113647 | Loss: 1.3201470375061035
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.372931569814682 | Loss: 1.4159376621246338
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.3703381776809693 | Loss: 1.3599646091461182
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.4003482460975647 | Loss: 1.550398588180542
Epochs is 3222 | Loss is 1.4003482460975647
[GPU 0] Epochs 3223, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.5123850107192993 | Loss: 1.5123850107192993
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.5053802132606506 | Loss: 1.498375415802002
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.5140729347864788 | Loss: 1.5314583778381348
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.5069858133792877 | Loss: 1.4857244491577148
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.4660905838012694 | Loss: 1.3025096654891968
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.4708768328030903 | Loss: 1.4948080778121948
Epochs is 3223 | Loss is 1.4708768328030903
[GPU 0] Epochs 3224, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.3709356784820557 | Loss: 1.3709356784820557
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.4558007717132568 | Loss: 1.540665864944458
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.4261659383773804 | Loss: 1.3668962717056274
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.473639041185379 | Loss: 1.616058349609375
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.4328136205673219 | Loss: 1.2695119380950928
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.465046803156535 | Loss: 1.6262127161026
Epochs is 3224 | Loss is 1.465046803156535
[GPU 0] Epochs 3225, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.3825948238372803 | Loss: 1.3825948238372803
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.424091100692749 | Loss: 1.4655873775482178
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.4052468140920003 | Loss: 1.367558240890503
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.4167110621929169 | Loss: 1.4511038064956665
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.4345208406448364 | Loss: 1.5057599544525146
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.440685252348582 | Loss: 1.4715073108673096
Epochs is 3225 | Loss is 1.440685252348582
[GPU 0] Epochs 3226, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.2913470268249512 | Loss: 1.2913470268249512
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.3985633850097656 | Loss: 1.50577974319458
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.384657621383667 | Loss: 1.3568460941314697
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.3839967250823975 | Loss: 1.3820140361785889
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.4068158149719239 | Loss: 1.4980921745300293
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.4147093097368877 | Loss: 1.4541767835617065
Epochs is 3226 | Loss is 1.4147093097368877
[GPU 0] Epochs 3227, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.5499746799468994 | Loss: 1.5499746799468994
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.4688571691513062 | Loss: 1.387739658355713
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.4621906280517578 | Loss: 1.4488575458526611
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.4180741906166077 | Loss: 1.2857248783111572
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.41070556640625 | Loss: 1.3812310695648193
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.4099268515904744 | Loss: 1.4060332775115967
Epochs is 3227 | Loss is 1.4099268515904744
[GPU 0] Epochs 3228, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.3268401622772217 | Loss: 1.3268401622772217
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.3375039100646973 | Loss: 1.3481676578521729
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.3084947268168132 | Loss: 1.250476360321045
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.3433343768119812 | Loss: 1.4478533267974854
[GPU 0] Step/Steps: 4/6 | Total Loss: 1.33056583404541 | Loss: 1.279491662979126
[GPU 0] Step/Steps: 5/6 | Total Loss: 1.3657692074775696 | Loss: 1.5417860746383667
Epochs is 3228 | Loss is 1.3657692074775696
[GPU 0] Epochs 3229, BatchSize: 1 | Steps: 6
[GPU 0] Step/Steps: 0/6 | Total Loss: 1.248504638671875 | Loss: 1.248504638671875
[GPU 0] Step/Steps: 1/6 | Total Loss: 1.3629990220069885 | Loss: 1.477493405342102
[GPU 0] Step/Steps: 2/6 | Total Loss: 1.356723427772522 | Loss: 1.3441722393035889
[GPU 0] Step/Steps: 3/6 | Total Loss: 1.370571792125702 | Loss: 1.4121168851852417
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** JOB 84425 ON a100-11 CANCELLED AT 2023-10-06T13:07:17 ***
slurmstepd: error: *** STEP 84425.0 ON a100-11 CANCELLED AT 2023-10-06T13:07:17 ***
