
----------------------------------------------------------------------------
  cuda:
----------------------------------------------------------------------------
     Versions:
        cuda/10.2
        cuda/11.0
        cuda/11.2
        cuda/11.3
        cuda/11.4
        cuda/11.5
        cuda/11.6
        cuda/11.7
        cuda/11.8
        cuda/12.0

----------------------------------------------------------------------------
  For detailed information about a specific "cuda" package (including how to load the modules) use the module's full name.
  Note that names that have a trailing (E) are extensions provided by other modules.
  For example:

     $ module spider cuda/12.0
----------------------------------------------------------------------------

 


CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.
To initialize your shell, run

    $ conda init <SHELL_NAME>

Currently supported shells are:
  - bash
  - fish
  - tcsh
  - xonsh
  - zsh
  - powershell

See 'conda init --help' for more information and options.

IMPORTANT: You may need to close and restart your shell after running 'conda init'.


/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/main.py:109: UserWarning: Found total gpus 2
  warnings.warn("Found total gpus {}".format(args.ngpus_per_node))
/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/karimimonsefi.1/miniconda3/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/main.py:135: UserWarning: 0 gpu 0
  warnings.warn(f"{args.rank} gpu {args.gpu}")
/home/karimimonsefi.1/SSL_VAN/pretrain/main.py:135: UserWarning: 1 gpu 1
  warnings.warn(f"{args.rank} gpu {args.gpu}")
/home/karimimonsefi.1/SSL_VAN/pretrain/main.py:137: UserWarning: Batch size is: 1 epochs 15000
  warnings.warn(f"Batch size is: {args.batch_size} epochs {args.max_epochs}")
/home/karimimonsefi.1/SSL_VAN/pretrain/main.py:144: UserWarning: Total parameters count 35225682
  warnings.warn(f"Total parameters count {pytorch_total_params}")
/home/karimimonsefi.1/SSL_VAN/pretrain/main.py:147: UserWarning: Total args.checkpoint True
  warnings.warn(f"Total args.checkpoint {args.checkpoint}")
/home/karimimonsefi.1/SSL_VAN/pretrain/main.py:156: UserWarning:  Best url model is pre_train_64-128-256-512_3-4-6-3_8-8-4-4_vae_inferer_valid_loader_PREVANV4__best.pt, final model url is pre_train_64-128-256-512_3-4-6-3_8-8-4-4_vae_inferer_valid_loader_PREVANV4__final.pt
  warnings.warn(f" Best url model is {args.best_model_url}, final model url is {args.final_model_url}")
/home/karimimonsefi.1/SSL_VAN/pretrain/main.py:144: UserWarning: Total parameters count 35225682
  warnings.warn(f"Total parameters count {pytorch_total_params}")
/home/karimimonsefi.1/SSL_VAN/pretrain/main.py:147: UserWarning: Total args.checkpoint True
  warnings.warn(f"Total args.checkpoint {args.checkpoint}")
/home/karimimonsefi.1/SSL_VAN/pretrain/main.py:156: UserWarning:  Best url model is pre_train_64-128-256-512_3-4-6-3_8-8-4-4_vae_inferer_valid_loader_PREVANV4__best.pt, final model url is pre_train_64-128-256-512_3-4-6-3_8-8-4-4_vae_inferer_valid_loader_PREVANV4__final.pt
  warnings.warn(f" Best url model is {args.best_model_url}, final model url is {args.final_model_url}")
/home/karimimonsefi.1/SSL_VAN/pretrain/main.py:182: UserWarning: => loaded checkpoint 'True' (epoch 6) (bestacc 6.214603423860338)
  warnings.warn("=> loaded checkpoint '{}' (epoch {}) (bestacc {})".format(
/home/karimimonsefi.1/SSL_VAN/pretrain/main.py:182: UserWarning: => loaded checkpoint 'True' (epoch 6) (bestacc 6.214603423860338)
  warnings.warn("=> loaded checkpoint '{}' (epoch {}) (bestacc {})".format(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:114: UserWarning: Writing Tensorboard logs to ./runs/pre_train_1/test_log
  warnings.warn(f"Writing Tensorboard logs to {args.logdir}")
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:124: UserWarning: 0  Tue Jun 13 08:16:10 2023  Epoch: 6
  warnings.warn(f"{args.rank}  {time.ctime()}  Epoch: {epoch}")
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:124: UserWarning: 1  Tue Jun 13 08:16:10 2023  Epoch: 6
  warnings.warn(f"{args.rank}  {time.ctime()}  Epoch: {epoch}")
Dataset 1 LUNA16: OK number of data: 842
Dataset 2 Covid 19: OK number of data: 722
Dataset 3 HNSCC: OK number of data: 954
Dataset 4 TCIA Colon: OK number of data: 1532
Dataset 5 TCIA LIDC: OK number of data: 450
Dataset all training: number of data: 4500
loader is ready
Dataset 1 LUNA16: OK number of data: 842
Dataset 2 Covid 19: OK number of data: 722
Dataset 3 HNSCC: OK number of data: 954
Dataset 4 TCIA Colon: OK number of data: 1532
Dataset 5 TCIA LIDC: OK number of data: 450
Dataset all training: number of data: 4500
loader is ready
[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 0/2250  loss: 6.2146  time 60.27s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 1/2250  loss: 6.2146  time 1.12s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 2/2250  loss: 6.2146  time 1.10s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 3/2250  loss: 6.2146  time 1.26s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 4/2250  loss: 6.2146  time 1.08s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 5/2250  loss: 6.2146  time 1.07s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 6/2250  loss: 6.2146  time 1.18s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 7/2250  loss: 6.2146  time 1.12s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 8/2250  loss: 6.2146  time 1.21s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 9/2250  loss: 6.2146  time 1.10s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 10/2250  loss: 6.2146  time 1.14s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 11/2250  loss: 6.2146  time 1.18s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 12/2250  loss: 6.2146  time 1.21s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 13/2250  loss: 6.2146  time 1.17s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 14/2250  loss: 6.2146  time 1.00s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 15/2250  loss: 6.2146  time 1.11s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 16/2250  loss: 6.2146  time 1.10s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 17/2250  loss: 6.2146  time 1.20s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 18/2250  loss: 6.2146  time 1.14s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 19/2250  loss: 6.2146  time 1.08s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 20/2250  loss: 6.2146  time 1.10s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 21/2250  loss: 6.2146  time 13.70s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 22/2250  loss: 6.2146  time 0.98s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 23/2250  loss: 6.2146  time 1.17s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 24/2250  loss: 6.2146  time 1.12s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 25/2250  loss: 6.2146  time 1.12s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 26/2250  loss: 6.2146  time 1.09s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 27/2250  loss: 6.2146  time 1.22s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 28/2250  loss: 6.2146  time 1.04s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 29/2250  loss: 6.2146  time 0.96s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 30/2250  loss: 6.2146  time 1.04s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 31/2250  loss: 6.2146  time 1.07s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 32/2250  loss: 6.2146  time 1.14s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 33/2250  loss: 6.2146  time 1.09s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 34/2250  loss: 6.2146  time 1.21s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 35/2250  loss: 6.2146  time 1.10s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 36/2250  loss: 6.2146  time 1.00s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 37/2250  loss: 6.2146  time 1.12s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 38/2250  loss: 6.2146  time 1.02s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 39/2250  loss: 6.2146  time 1.06s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 40/2250  loss: 6.2146  time 1.06s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 41/2250  loss: 6.2146  time 6.41s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 42/2250  loss: 6.2146  time 1.06s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 43/2250  loss: 6.2146  time 2.29s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 44/2250  loss: 6.2146  time 1.07s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 45/2250  loss: 6.2146  time 1.27s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 46/2250  loss: 6.2146  time 1.16s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 47/2250  loss: 6.2146  time 1.11s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 48/2250  loss: 6.2146  time 1.05s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 49/2250  loss: 6.2146  time 8.13s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 50/2250  loss: 6.2146  time 1.07s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 51/2250  loss: 6.2146  time 2.18s
  warnings.warn(
/home/karimimonsefi.1/SSL_VAN/pretrain/training.py:77: UserWarning: Epoch 6/15000 52/2250  loss: 6.2146  time 1.05s
  warnings.warn(
slurmstepd: error: *** JOB 58994 ON a100-09 CANCELLED AT 2023-06-13T08:18:42 ***
